Beyond the traditional security challenges of running workloads in public clouds, as organizations integrate AI into their workflows, they must account for additional risks related to data protection, model security, compliance, adversarial attacks, and responsible AI governance. 

An organization's AI CoE plays a key role in setting guidelines, ensuring compliance, and supporting teams in secure AI implementation. The CoE works with existing security and workload teams to ensure that security considerations are embedded into all AI-related processes and aligned with organizational security policies.

Ensuring the security of AI workloads requires continuous collaboration with security teams to integrate AI-specific safeguards into enterprise policies. An AI CoE can define which security frameworks are relevant for the organization, align those frameworks with compliance, and support teams in ensuring that AI workloads are secure and compliant.

## Security controls and guardrails

The AI CoE should determine methods and practices for secure and responsible AI workload deployment and operation. These include but aren't limited to:

- Implement guardrails to detect and mitigate risks such as prompt injection attacks and unsafe outputs.
- Require adversarial testing and prompt attack simulations to detect and neutralize threats.
- Secure AI pipelines with strict access controls, API security, and model rollback mechanisms.
- Require security-focused model validation to prevent vulnerabilities in GenAI applications.
- Determine whether your use case is an ethical target for AI and maintaining ethical standards throughout the planning and implementation phases to ensure that you're building a responsible system.
- Establish version control policies to prevent the unintended use of outdated or manipulated models.
- Define security standards that integrate real-time monitoring for model drift, data exposure, and anomalous AI behavior.
- Work with IT security teams to harden API security, ensuring AI model endpoints are protected from unauthorized queries and misuse.
- Prevent unauthorized AI model export or transfer, ensuring proprietary AI systems remain protected.
- Ensure role-based access control (RBAC) and identity management for AI model usage and modification.
- Establish real-time security monitoring for AI anomalies, adversarial behaviors, and suspicious patterns.
- Implement automated logging and forensic tools to investigate security events and potential breaches.
- Track security incidents and unauthorized AI access within AI performance dashboards.
- Ensure that hardening processes are applied to AI workload infrastructure.

## Security of organizational data

The AI CoE's role in the security of organizational data isn't to manage data holistically but to provide guidance, AI-specific standards, and frameworks that address the unique needs of AI systems. These responsibilities include: 

- Preparing datasets for AI training and inference
- Generating and validating synthetic data
- Addressing bias to promote fairness
- Implementing processes for data exploration, clustering, and augmentation. 

Broader data management responsibilities, such as governance and architecture and pipeline management, are handled by specialized Data Platform teams or Data & Analytics teams. 

The AI CoE should define the following methods and practices:

- Security best practices for data ingestion, storage, and processing to ensure AI models are trained on validated, high-quality datasets.
- Collaborate with data security teams to enforce encryption, anonymization, and synthetic data validation tailored for AI use cases.
- Define safeguards that prevent data poisoning attacks that could manipulate model training through adversarial or biased input data.
- Develop security-aligned data curation guidelines to ensure compliance with Responsible AI principles, including bias mitigation and ethical dataset construction.
- Ensure secure data practice including enforcing the encryption data in transit and at rest, the isolation of sensitive assets with fine-grained access controls, and the enforcement of data loss prevention policies.
