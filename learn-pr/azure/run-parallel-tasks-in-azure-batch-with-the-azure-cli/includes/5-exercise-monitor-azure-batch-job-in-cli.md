If you're using Azure Batch to run intensive tasks, you'll often want to know how the tasks are going.

As the solution architect for the non-profit, you'll need ways to access what is happening in Azure Batch. You also need to determine whether the nodes and tasks are working, how far they've progressed, and whether they have produced output files that can be downloaded.

In this unit, you'll create a job similar to the one in the previous unit, monitor the progress of its tasks, and download the files that the tasks produce as output, all using the Azure CLI.

>[!IMPORTANT]
>The exercises in this module are optional. To complete the exercises, you'll need your own Azure subscription.

## Monitor tasks using the CLI

Azure Batch handles all the details of creating and managing compute nodes and scheduling jobs to run on those nodes.

When you created tasks in the last unit, Azure Batch queued them to run in the pool. As nodes were determined to have available capacity, Azure Batch scheduled the tasks to run on those nodes.

At the end of the last unit, we deleted the job, which had the effect of deleting all its tasks. We'll now create a new job and tasks. It's worth noting that deleting and recreating tasks is a fairly quick operation, and allows you to easily separate out different experiments and projects in Azure Batch. By contrast, deleting and recreating higher-level Batch entities (like accounts) takes more time because the Batch pool has to be recreated and virtual machines allocated.

1. Sign into the [Azure portal](https://portal.azure.com/).

1. Open the Cloud Shell by clicking **>_** in the top menu.

1. Run the following command in the Cloud Shell in order to create a new Batch job:

    ```azurecli
    az batch job create \
     --id myjob2 \
     --pool-id mypool
    ```

    We name it differently to avoid any conflict with the job from the previous unit, which will have been scheduled for deletion but not necessarily deleted yet.
1. Run the following command to create Batch tasks within this new job:

    ```azurecli
    for i in {1..10}
    do
       az batch task create \
        --task-id mytask$i \
        --job-id myjob2 \
        --command-line "/bin/bash -c 'echo \$(printenv | grep \AZ_BATCH_TASK_ID) processed by; echo \$(printenv | grep \AZ_BATCH_NODE_ID)'"
    done
    ```

1. Run the following command in the Cloud Shell to view the status of one of the tasks you created:

    ```azurecli
    az batch task show \
     --job-id myjob2 \
     --task-id mytask1
    ```

## Download task output using the CLI  

To check that the batch job executed correctly, you can download and examine the files it created:

1. Run the following command in the Cloud Shell to show a table of all the files generated by one of the tasks you've created:

    ```azurecli
    az batch task file list \
     --job-id myjob2 \
     --task-id mytask5 \
     --output table
    ```

    > [!NOTE]
    > If you see a `The files of the specified task cannot be accessed as the task state is still active` error message, wait a few minutes, and then run the command again.

1. Run the following command in the Cloud Shell to create a dedicated directory for task outputs and navigate into it:

    ```bash
    mkdir taskoutputs && cd taskoutputs
    ```

1. Run the following command in the Cloud Shell to download the files generated by all the tasks you created:

    ```azurecli
    for i in {1..10}
    do
    az batch task file download \
        --job-id myjob2 \
        --task-id mytask$i \
        --file-path stdout.txt \
        --destination ./stdout$i.txt
    done
    ```

    Tasks have a default working directory, and by default their work is directed to stdout.txt. By looping through we can redirect stdout.txt to numbered versions of stdout.txt, each of which shows the work of a given task and which node was used to execute it.

1. View the text contents of a couple of the sample-generated files:

    ```azurecli
    cat stdout1.txt && cat stdout2.txt
    ```

    This output shows different tasks being scheduled onto different nodes as the Batch scheduler processes them.

    Again, we'll leave the Azure Batch account and pool of worker nodes in place for use in the next unit, but we'll delete the Batch job. Because the Batch job acts as a container for its Batch tasks, these tasks are also deleted.

1. Delete the Batch job:

    ```azurecli
    az batch job delete --job-id myjob2 -y
    ```