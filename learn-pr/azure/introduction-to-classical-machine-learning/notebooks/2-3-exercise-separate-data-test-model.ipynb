{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Supervised learning\n",
    "\n",
    "Recall our farming scenario, in which we want to look at how January temperatures have changed over time. Now, we'll build a model that achieves this by using supervised learning. \n",
    "\n",
    "With many libraries, we can build a model in only a few lines of code. Here, we'll break down the process into steps so that we can explore how things work.\n",
    "\n",
    "## Four components\n",
    "Recall that there are four key components to supervised learning: the data, the model, the cost function, and the optimizer. Let's inspect these one at a time.\n",
    "\n",
    "### 1. The data\n",
    "\n",
    "We'll use publicly available weather data for Seattle. Let's load that and restrict it to January temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/m0b_optimizer.py\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/seattleWeather_1948-2017.csv\n",
    "\n",
    "# Load a file that contains weather data for Seattle\n",
    "data = pandas.read_csv('seattleWeather_1948-2017.csv', parse_dates=['date'])\n",
    "\n",
    "# Keep only January temperatures\n",
    "data = data[[d.month == 1 for d in data.date]].copy()\n",
    "\n",
    "\n",
    "# Print the first and last few rows\n",
    "# Remember that with Jupyter notebooks, the last line of \n",
    "# code is automatically printed\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have data from 1948 to 2017, split across 2,170 rows. \n",
    "\n",
    "We'll analyze the relationship between `date` and daily minimum temperatures. Let's take a quick look at our data as a graph. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Let's take a quick look at our data\n",
    "\n",
    "plt.scatter(data[\"date\"], data[\"min_temperature\"])\n",
    "\n",
    "# add labels and legend\n",
    "plt.xlabel(\"date\")\n",
    "plt.ylabel(\"min_temperature\")\n",
    "plt.title(\"January Temperatures (Â°F)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning usually works best when the X and Y axes have roughly the same range of values. We'll cover why in later learning material. For now, let's just scale our data slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# This block of code scales and offsets the data slightly, which helps the training process\n",
    "# You don't need to understand this code. We'll cover these concepts in later learning material\n",
    "\n",
    "# Offset date into number of years since 1982\n",
    "data[\"years_since_1982\"] = [(d.year + d.timetuple().tm_yday / 365.25) - 1982 for d in data.date]\n",
    "\n",
    "# Scale and offset temperature so that it has a smaller range of values\n",
    "data[\"normalised_temperature\"] = (data[\"min_temperature\"] - np.mean(data[\"min_temperature\"])) / np.std(data[\"min_temperature\"])\n",
    "\n",
    "# Graph\n",
    "plt.scatter(data[\"years_since_1982\"], data[\"normalised_temperature\"])\n",
    "# add labels and legend\n",
    "plt.xlabel(\"years_since_1982\")\n",
    "plt.ylabel(\"normalised_temperature\")\n",
    "plt.title(\"January Temperatures (Normalised)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The model\n",
    "\n",
    "We'll select a simple linear-regression model. This model uses a line to make estimates. You might have come across trendlines like these before when making graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel:\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Creates a new MyModel\n",
    "        '''\n",
    "        # Straight lines described by two parameters:\n",
    "        # The slope is the angle of the line\n",
    "        self.slope = 0\n",
    "        # The intercept moves the line up or down\n",
    "        self.intercept = 0\n",
    "\n",
    "    def predict(self, date):\n",
    "        '''\n",
    "        Estimates the temperature from the date\n",
    "        '''\n",
    "        return date * self.slope + self.intercept\n",
    "\n",
    "# Create our model ready to be trained\n",
    "model = MyModel()\n",
    "\n",
    "print(\"Model made!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wouldn't normally use a model before it's been trained, but for the sake of learning, let's take a quick look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model parameters before training: {model.intercept}, {model.slope}\")\n",
    "\n",
    "# Look at how well the model does before training\n",
    "print(\"Model visualised before training:\")\n",
    "\n",
    "plt.scatter(data[\"years_since_1982\"], data[\"normalised_temperature\"])\n",
    "plt.plot(data[\"years_since_1982\"], model.predict(data[\"years_since_1982\"]), 'r', label='Fitted line')\n",
    "\n",
    "                                                 \n",
    "# add labels and legend\n",
    "plt.xlabel(\"years_since_1982\")\n",
    "plt.ylabel(\"normalised_temperature\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that before training, our model (the red line) isn't useful at all. It always simply predicts zero.\n",
    "\n",
    "### 3. The cost (objective) function\n",
    "\n",
    "Our next step is to create a _cost function_ (_objective function_).\n",
    "\n",
    "These functions in supervised learning compare the model's estimate to the correct answer. In our case, our label is temperature, so our cost function compares the estimated temperature to temperatures seen in the historical records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(actual_temperatures, estimated_temperatures):\n",
    "    '''\n",
    "    Calculates the difference between actual and estimated temperatures\n",
    "    Returns the difference, and also returns the squared difference (the cost)\n",
    "\n",
    "    actual_temperatures: One or more temperatures recorded in the past\n",
    "    estimated_temperatures: Corresponding temperature(s) estimated by the model\n",
    "    '''\n",
    "\n",
    "    # Calculate the difference between actual temperatures and those\n",
    "    # estimated by the model\n",
    "    difference = estimated_temperatures - actual_temperatures\n",
    "\n",
    "    # Convert to a single number that tells us how well the model did\n",
    "    # (smaller numbers are better)\n",
    "    cost = sum(difference ** 2)\n",
    "\n",
    "    return difference, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. The optimizer\n",
    "\n",
    "The optimizer's role is to guess new parameter values for the model. \n",
    "\n",
    "We haven't covered optimizers in detail yet, so to make things simple, we'll use an prewritten optimizer. You don't need to understand how this works, but if you're curious, you can find it in our GitHub repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from m0b_optimizer import MyOptimizer\n",
    "\n",
    "# Create an optimizer\n",
    "optimizer = MyOptimizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The training loop\n",
    "\n",
    "Let's put these components together so that they train the model. \n",
    "\n",
    "First, let's make a function that performs one iteration of training. Read each step carefully in the following code. If you want, add some `print()` statements inside the method to help you see the training in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_iteration(model_inputs, true_temperatures, last_cost:float):\n",
    "    '''\n",
    "    Runs a single iteration of training.\n",
    "\n",
    "\n",
    "    model_inputs: One or more dates to provide the model (dates)\n",
    "    true_temperatues: Corresponding temperatures known to occur on those dates\n",
    "\n",
    "    Returns:\n",
    "        A Boolean, as to whether training should continue\n",
    "        The cost calculated (small numbers are better)\n",
    "    '''\n",
    "\n",
    "    # === USE THE MODEL ===\n",
    "    # Estimate temperatures for all data that we have\n",
    "    estimated_temperatures = model.predict(model_inputs)\n",
    "\n",
    "    # === OBJECTIVE FUNCTION ===\n",
    "    # Calculate how well the model is working\n",
    "    # Smaller numbers are better \n",
    "    difference, cost = cost_function(true_temperatures, estimated_temperatures)\n",
    "\n",
    "    # Decide whether to keep training\n",
    "    # We'll stop if the training is no longer improving the model effectively\n",
    "    if cost >= last_cost:\n",
    "        # Stop training\n",
    "        return False, cost\n",
    "    else:\n",
    "        # === OPTIMIZER ===\n",
    "        # Calculate updates to parameters\n",
    "        intercept_update, slope_update = optimizer.get_parameter_updates(model_inputs, cost, difference)\n",
    "\n",
    "        # Change the model parameters\n",
    "        model.slope += slope_update\n",
    "        model.intercept += intercept_update\n",
    "\n",
    "        return True, cost\n",
    "\n",
    "print(\"Training method ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a few iterations manually, so that you can watch how training works.\n",
    "\n",
    "Run the following code several times and note how the model changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "print(f\"Model parameters before training:\\t\\t{model.intercept:.8f},\\t{model.slope:.8f}\")\n",
    "\n",
    "continue_loop, cost = train_one_iteration(model_inputs = data[\"years_since_1982\"],\n",
    "                                                    true_temperatures = data[\"normalised_temperature\"],\n",
    "                                                    last_cost = math.inf)\n",
    "\n",
    "print(f\"Model parameters after 1 iteration of training:\\t{model.intercept:.8f},\\t{model.slope:.8f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'll take thousands of iterations to train the model well, so let's wrap it in a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Start the loop\n",
    "print(\"Training beginning...\")\n",
    "last_cost = math.inf\n",
    "i = 0\n",
    "continue_loop = True\n",
    "while continue_loop:\n",
    "\n",
    "    # Run one iteration of training\n",
    "    # This will tell us whether to stop training, and also what\n",
    "    # the cost was for this iteration\n",
    "    continue_loop, last_cost = train_one_iteration(model_inputs = data[\"years_since_1982\"],\n",
    "                                                    true_temperatures = data[\"normalised_temperature\"],\n",
    "                                                    last_cost = last_cost)\n",
    "   \n",
    "    # Print the status\n",
    "    if i % 400 == 0:\n",
    "        print(\"Iteration:\", i)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    \n",
    "print(\"Training complete!\")\n",
    "print(f\"Model parameters after training:\\t{model.intercept:.8f},\\t{model.slope:.8f}\")\n",
    "\n",
    "plt.scatter(data[\"years_since_1982\"], data[\"normalised_temperature\"])\n",
    "plt.plot(data[\"years_since_1982\"], model.predict(data[\"years_since_1982\"]), 'r', label='Fitted line')\n",
    "                              \n",
    "# add labels and legend\n",
    "plt.xlabel(\"years_since_1982\")\n",
    "plt.ylabel(\"normalised_temperature\")\n",
    "plt.legend()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how now that the model is trained, it's giving more sensible predictions about January temperatures.\n",
    "\n",
    "Interestingly, the model shows temperatures going up over time. Perhaps we need to stop feeding grain to our elk earlier in the year!\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this exercise, we split up supervised learning into its individual stages to see what's going on in code when we use third-party libraries. The important point to take away is how these pieces fit together. Note that most parts of this process require data."
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "conda-env-azureml_py38-py"
  },
  "kernelspec": {
   "display_name": "azureml_py38",
   "language": "python",
   "name": "conda-env-azureml_py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
