Logging is an essential element of any commercial application. Logging gives you insight into how, when, where, and why significant system events occurred. When logging is enabled, you can track the sequence of operations that led to a specific outcome.

## What is logging?

You use logging to maintain a history of the work that an application does. The information can be helpful in debugging and analyzing performance problems. The data can provide insight into how users are interacting with the system. It might help you identify security weaknesses or users who are attempting to attack the system. You also can use logging as the basis for an audit trail of activity.

Logging should be unobtrusive, and it shouldn't cause you to modify the logical flow of a web application. The simplest form of logging is printing messages at strategic points in an application. In a web app, you might consider tracking each time a webpage is loaded in a web browser. If the webpage completes a series of operations, you might also display a message before and after each operation. Later, we describe more sophisticated approaches to logging. Right now, you'll learn how to customize when, how, and where log records are written.

When you add logging to an application, there are several points to consider:

- What information should you record in a log and in what format? 
  
  The information that you write to a log depends primarily on your reason for using logging. If you use logging to trace the logical flow of progress through the application for debugging, the data you record might consist of human-readable text (for example, "Function *x* has started with parameters *y* and *z*"). If the purpose of logging is to track performance, the information you capture likely will be in a format that can be consumed by the tools you use to analyze performance. The format can be binary, XML, or another well-defined layout, but it's unlikely to be free-form text. Similarly, your log data might be part of an audit trail that's needed to maintain the historical integrity of the chain of events that led to the application being in a specific state. Performance and audit data must be tagged with the current date and time.

- Where should the logging output be sent? 

  When you debug a desktop app, you can write messages to the screen. If you're using a tool like Visual Studio, you might choose to send messages to the Visual Studio Debug window. For a web app that's hosted in an on-premises server, you can record log data in a local file. However, for a production web app that's running in an environment like Azure App Service, you must have a repository that's more accessible. You might not have direct access to the file system of the system on which the web app is running. Also, if the web app scales out across multiple servers, writing to the local file system causes the log to become fragmented. 
  
  Security is another concern. A log might contain personal information that should be kept confidential, especially if the log also acts as an audit trail of events. You also might need to ensure that the log can't be accessed by an unauthorized user. Keeping the log data in a more centralized, secure storage mechanism like Azure Blob storage might be a preferable and more scalable solution.

- How long should the messages be saved?

  The lifetime and organization of log data is driven in part by the reason for capturing the information. If the log is used purely for debugging, the lifetime is likely to be brief; the data can be deleted when the debugging session is finished. If you capture data to track performance, after the data has been assimilated, aggregated, and analyzed, it often can be removed or archived. An archive might prove useful for tracking historical performance trends, but it likely can be discarded after a short while. Data that's captured for audit purposes might need to be held indefinitely, depending on the nature of the application and any regulatory requirements for retaining records. In this case, the repository that holds the log data needs to keep an indefinite, and possibly a large amount of data for a long time.

- In a multiuser system, how do you make sense of the logging output that's generated by potentially many thousands of concurrent users?

  In a large-scale system, log messages that are generated by the interactions of each user in the system are interwoven in a large mass of data. Tracking the path of an individual user or request requires correlation. To achieve correlation, each user session must generate a unique key that can be attached to each log message that is generated by that session. The correlation key domain must support sorting and searching so that the data for each individual session is isolated. 

## Incorporate logging into an ASP.NET web application

One of the most familiar logging mechanisms for .NET developers is implemented by the types in the system.diagnostics namespace. The model used by system.diagnostics is based on *listeners*. A listener listens for log messages that are sent by the application. Then, it writes the log messages to a log destination. Listeners are provided for the console, text files, the event log, and other system components. You also can update performance counters. In an ASP.NET web application, you configure the listeners in the *web.config* file. You write messages by using the methods of the static **System.Diagnostics.Trace** object in your code. Each message is sent to every configured trace listener. For more information, see [Trace and instrument applications](https://docs.microsoft.com/dotnet/framework/debug-trace-profile/tracing-and-instrumenting-applications).

If you're building ASP.NET Core web apps, you can use the built-in logging API that's available in the Microsoft.Extensions.Logging namespace. This API works in conjunction with multiple built-in logging providers. Each provider sends log data to different destinations. The logging framework is extensible and it's supported by numerous third-party providers. For details, see [Logging in .NET Core and ASP.NET Core](https://docs.microsoft.com/aspnet/core/fundamentals/logging/).

Another approach to logging is to use a third-party logging framework. Many powerful frameworks are available. The frameworks often provide features above and beyond the ones that are available through the system.diagnostics namespace or basic ASP.NET Core logging. Popular logging frameworks for .NET Framework applications include [Apache Log4Net](https://logging.apache.org/log4net/), [NLog](https://nlog-project.org/), and [Serilog](https://serilog.net/). 

Like the system.diagnostics namespace, Log4Net, NLog, and Serilog support structured logging and log levels. In structured logging, additional system-generated metadata can be written as part of the log message. The data can include a user or session ID, the current date and time, and log message correlation information. You can use log levels to send log messages to different destinations, depending on the severity of the message. For example, you might want to send all application error messages to a destination that you use to track issues with your application and send information messages about an operation to the audit log. You can even selectively turn logging on and off for different log levels. For example, you might want to enable or disable log messages associated with debugging. Logging affects performance, and it's important to reduce the overhead when logging isn't required. You can set most logging options by using configuration files instead of by revising your code.

Third-party logging frameworks provide drivers for multiple log destinations. For example, NLog currently provides more than 80 targets for log information, including most of the popular databases. Developers can take advantage of the extensible nature of these frameworks to add their own custom destinations and to publish drivers for additional targets.

Most logging frameworks use an *appender* model, in which data is written to the end of (appended to) the target. What constitutes *the end* depends on the target. If the destination is a relational table, an appender most likely will add a new row to the table. If the destination is a file, the appender will add log records to the end of the file. In many cases, you can set up the appender to implement a circular or *rolling* mechanism, in which you set a maximum size for the destination and older log records are eventually overwritten. Many appenders provide facilities for compacting and archiving log data before it is overwritten.
