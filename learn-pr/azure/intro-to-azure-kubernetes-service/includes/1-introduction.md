Using containers in software development has become popular due to the ease of use and versatility. Containers make it easy to package and deploy an application to any compute environment for tests, scale, and go live. When your application meets higher demand, you can easily scale out your services by deploying more container instances. Containers are also less resource intensive than virtual machines. This efficiency allows you to make better use of compute resources, and that saves you money.

The standard container management runtime is focused on managing individual containers. However, there are times where you want to scale and have multiple containers working together. Scaling multiple containers becomes challenging as several factors need consideration when managing multiple containers. Suppose you need to handle load balancing, security, network connectivity, and deployment. To help make this process easier, it's common to use a container management platform such as Kubernetes.

Suppose you run a company that provides an asset tracking solution to customers worldwide. Your tracking solution is built and deployed as microservices, which are then packaged into containers. You're using the containerized instances to quickly deploy into new customer regions and scale resources as needed to meet customer demand globally. You're tasked to use a container orchestration platform that simplifies the process to develop, deploy, and manage containerized applications.

Here, you see how Azure Kubernetes Service (AKS) makes it simple to manage a hosted Kubernetes environment in Azure. We hope to aid you in your decision if AKS is a good choice as a Kubernetes platform for your business.

## Learning objectives

In this module, you'll:

- Evaluate whether Azure Kubernetes Service is an appropriate Kubernetes orchestration platform for you
- Describe how the components of Azure Kubernetes Service work to support compute container orchestration

## Prerequisites

- Basic understanding of microservices
