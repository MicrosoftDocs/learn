In this module, you've learned how to enable eye-tracking for HoloLens 2 and add eye-tracking to objects to trigger actions when the user looks at the objects. You also learned how to create speech commands and how to control them globally. Finally, you also learned how to control local speech commands that require the user to look at the object that controls the speech command.

Including voice commands and eye-tracking can benefit some applications and some users, reducing the movement required for interactions.

## Next steps

You can continue to add eye-tracking and voice commands to your applications. Consider trying following interactions:

* Use eye gaze to select an object and move with your hands
* Change the color of an object by saying "Change color"
* Add multiple voice commands on a single object.

## Further reading

* Learn more about [Eye-Tracking](/windows/mixed-reality/mrtk-unity/features/input/eye-tracking/eye-tracking-basic-setup)

* Learn more about [Voice Commands](/windows/mixed-reality/design/voice-input)
