Congratulations on completing your introduction to regression! Let’s recap the important points.

We learned that regression looks for a continuous relationship between features and labels, usually explainable using simple math. We learned that models are named by two things:

* The type of curve that regression models fit. For example, linear regression looks for “straight line” relationships, while polynomial regression can work with non-linear relationships.
* How many variables they use: simple regression uses one feature, while multiple uses multiple features.

We also covered R<sup>2</sup> values, which we use to assess how well our model fits the data, with the number 0 meaning the model is completely ineffective, and 1 meaning it fits perfectly.

Finally, we learned about extrapolation – predicting values using features that are outside the range of our training data set. While we found this was easy using regression models, we saw how models could be unreasonable if the features were a long way from those in our training data.