{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d1109a5",
   "metadata": {},
   "source": [
    "# Exercise: Fitting a Polynomial Curve"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9efeb1ee",
   "metadata": {},
   "source": [
    "In this exercise, we'll have a look at a different type of regression called _polynomial regression_.\n",
    "In contrast to _linear regression_ ,which models relationships as straight lines, _polynomial regression_ models relationships as curves.\n",
    "\n",
    "Recall in our previous exercise how the relationship between `core_temperature` and `protein_content_of_last_meal` couldn't be properly explained using a straight line. In this exercise, we'll use _polynomial regression_ to fit a curve to the data instead.\n",
    "\n",
    "## Data visualization\n",
    "\n",
    "Let's start this exercise by loading and having a look at our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2d409a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "!pip install statsmodels\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
    "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/doggy-illness.csv\n",
    "\n",
    "#Import the data from the .csv file\n",
    "dataset = pandas.read_csv('doggy-illness.csv', delimiter=\"\\t\")\n",
    "\n",
    "#Let's have a look at the data\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9272f22e",
   "metadata": {},
   "source": [
    "# Simple Linear Regression\n",
    "\n",
    "Let's quickly jog our memory by performing the same _simple linear regression_ as we did in the previous exercise, using the `temperature` and `protein_content_of_last_meal` columns of the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c68026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Perform linear regression. This method takes care of\n",
    "# the entire fitting procedure for us.\n",
    "simple_formula = \"core_temperature ~ protein_content_of_last_meal\"\n",
    "simple_model = smf.ols(formula = simple_formula, data = dataset).fit()\n",
    "\n",
    "# Show a graph of the result\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(dataset[\"protein_content_of_last_meal\"], dataset[\"core_temperature\"])\n",
    "plt.title(\"Core Temperature vs Protein Content of Last Meal\")\n",
    "plt.xlabel(\"Protein Content of Last Meal\")\n",
    "plt.ylabel(\"Core Temperature\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a252489e",
   "metadata": {},
   "source": [
    "Notice how the relationship between the two variables is not truly linear. Looking at the plot, it's fairly clear to see that the points tend more heavily towards one side of the line, especially for the higher `core-temperature` and `protein_content_of_last_meal` values. \n",
    "\n",
    "A straight line might not be the best way to describe this relationship.\n",
    "\n",
    "Let's have a quick look at the model's R-Squared score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90292f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R-squared:\", simple_model.rsquared)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33c49c6f",
   "metadata": {},
   "source": [
    "That's quite a reasonable R-Squared score, but let's see if we can get an even better one!\n",
    "\n",
    "## Simple Polynomial Regression\n",
    "\n",
    "Let's fit a _simple polynomial regression_ this time. Similar to a _simple linear regression_, a _simple polynomial regression_ models the relationship between a label and a single feature. Unlike a _simple linear regression_, a _simple polynomial regression_ can explain relationships that aren't simply straight lines.\n",
    "\n",
    "In our example, we're going to use a three-parameter polynomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dc5d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Perform polynomial regression\n",
    "polynomial_formula = \"core_temperature ~ protein_content_of_last_meal + I(protein_content_of_last_meal**2)\"\n",
    "polynomial_model = smf.ols(formula=polynomial_formula, data=dataset).fit()\n",
    "\n",
    "# Scatter plot of the data\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(dataset[\"protein_content_of_last_meal\"], dataset[\"core_temperature\"], label=\"Data\", alpha=0.7)\n",
    "\n",
    "# Generate smooth x values for the trendline\n",
    "x_vals = np.linspace(dataset[\"protein_content_of_last_meal\"].min(), dataset[\"protein_content_of_last_meal\"].max(), 200)\n",
    "\n",
    "# Calculate predicted y values using the polynomial coefficients\n",
    "y_vals = (polynomial_model.params[2] * x_vals**2 +\n",
    "          polynomial_model.params[1] * x_vals +\n",
    "          polynomial_model.params[0])\n",
    "\n",
    "# Plot the trendline\n",
    "plt.plot(x_vals, y_vals, color=\"red\", label=\"Polynomial Trendline\")\n",
    "\n",
    "# Label axes and show plot\n",
    "plt.xlabel(\"Protein Content of Last Meal\")\n",
    "plt.ylabel(\"Core Temperature\")\n",
    "plt.title(\"Polynomial Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b07473",
   "metadata": {},
   "source": [
    "That looks a lot better already. Let's confirm by having a quick look at the R-Squared score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d5e4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R-squared:\", polynomial_model.rsquared)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c21dd2b",
   "metadata": {},
   "source": [
    "That's a better R-Squared score than the one obtained from the previous model! We can now confidently tell our vet to prioritize dogs who ate a high-protein diet the night before. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb95e9a6",
   "metadata": {},
   "source": [
    "Let's chart our model as a 3D chart. We'll view $X$ and $X^2$ as two separate parameters. Notice that our regression model is still a flat plane. This is why polynomial models are still considered to be `linear models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9da888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Create a grid of x and x² values\n",
    "x_vals = np.linspace(dataset.protein_content_of_last_meal.min(),\n",
    "                     dataset.protein_content_of_last_meal.max(), 50)\n",
    "x2_vals = x_vals**2\n",
    "x_grid, x2_grid = np.meshgrid(x_vals, x2_vals)\n",
    "\n",
    "# Compute z using the polynomial model's parameters\n",
    "z_vals = (polynomial_model.params[0]\n",
    "          + polynomial_model.params[1] * x_grid\n",
    "          + polynomial_model.params[2] * x2_grid)\n",
    "\n",
    "# Create the 3D plot\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the surface\n",
    "ax.plot_surface(x_grid, x2_grid, z_vals, alpha=0.6, cmap=\"viridis\", edgecolor=\"none\")\n",
    "\n",
    "# Add the original data points\n",
    "ax.scatter(dataset.protein_content_of_last_meal,\n",
    "           dataset.protein_content_of_last_meal**2,\n",
    "           dataset.core_temperature,\n",
    "           color=\"red\", label=\"Data Points\")\n",
    "\n",
    "# Axis labels and title\n",
    "ax.set_xlabel(\"x (Protein Content)\")\n",
    "ax.set_ylabel(\"x² (Protein Content Squared)\")\n",
    "ax.set_zlabel(\"Core Temperature\")\n",
    "ax.set_title(\"Polynomial Regression Surface\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cb0355d",
   "metadata": {},
   "source": [
    "## Extrapolating\n",
    "\n",
    "Let's see what happens if we extrapolate our data. We'd like to see if dogs that ate meals even higher in protein are expected to get even sicker.\n",
    "\n",
    "Let's start with the _linear regression_. We can set what range we'd like to extrapolate our data over by using the `x_range` argument in the plotting function. Let's extrapolate over the range `[0,100]`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881d3890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Scatter plot of the actual data\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(dataset[\"protein_content_of_last_meal\"], dataset[\"core_temperature\"], label=\"Data\", alpha=0.7)\n",
    "\n",
    "# Define extrapolation range\n",
    "x_vals = np.linspace(0, 100, 200)\n",
    "\n",
    "# Calculate the trendline using the simple linear model\n",
    "y_vals = simple_model.params[1] * x_vals + simple_model.params[0]\n",
    "\n",
    "# Plot the extrapolated trendline\n",
    "plt.plot(x_vals, y_vals, color=\"red\", label=\"Extrapolated Trendline\")\n",
    "\n",
    "# Label axes and add title/legend\n",
    "plt.xlabel(\"Protein Content of Last Meal\")\n",
    "plt.ylabel(\"Core Temperature\")\n",
    "plt.title(\"Extrapolated Linear Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57561d55",
   "metadata": {},
   "source": [
    "Next, we extrapolate the _polynomial regression_ over the same range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d264380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Scatter plot of the actual data\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(dataset[\"protein_content_of_last_meal\"], dataset[\"core_temperature\"], label=\"Data\", alpha=0.7)\n",
    "\n",
    "# Define extrapolation range\n",
    "x_vals = np.linspace(0, 100, 300)\n",
    "\n",
    "# Compute the polynomial trendline from the model parameters\n",
    "y_vals = (polynomial_model.params[2] * x_vals**2 +\n",
    "          polynomial_model.params[1] * x_vals +\n",
    "          polynomial_model.params[0])\n",
    "\n",
    "# Plot the extrapolated polynomial trendline\n",
    "plt.plot(x_vals, y_vals, color=\"purple\", label=\"Extrapolated Polynomial Trendline\")\n",
    "\n",
    "# Label axes and add title/legend\n",
    "plt.xlabel(\"Protein Content of Last Meal\")\n",
    "plt.ylabel(\"Core Temperature\")\n",
    "plt.title(\"Extrapolated Polynomial Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32c82a72",
   "metadata": {},
   "source": [
    "These two graphs predict two very different things!\n",
    "\n",
    "The extrapolated _polynolmial regression_ expects `core_temperature` to go down, while the extrapolated _linear regression_ expects linear expects `core_temperature` to go up.\n",
    "\n",
    "A quick look at the graphs obtained in the previous exercise confirms that we should expect the `core_temeprature` to rise, not fall, as the `protein_content_of_last_meal` increases.\n",
    "\n",
    "In general, it's not recommended to extrapolate from a _polynomial regression_ unless you have an a-priori reason to do so (which is only very rarely the case, so it's best to err on the side of caution and never extrapolate from  _polynomial regressions_).\n",
    "\n",
    "## Summary\n",
    "\n",
    "We covered the following concepts in this exercise:\n",
    "\n",
    "- Built _simple linear regression_ and _simple polynomial regression_ models.\n",
    "- Compared the performance of both models by plotting them and looking at R-Squared values.\n",
    "- Extrapolated the models over a wider range of values."
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "conda-env-azureml_py38-py"
  },
  "kernelspec": {
   "display_name": "py38_default",
   "language": "python",
   "name": "conda-env-azureml_py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "2a35a5d7a1695c145f6d485f5528d9f0e062df43578e4fcb0dcb8fc15dd48b38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
