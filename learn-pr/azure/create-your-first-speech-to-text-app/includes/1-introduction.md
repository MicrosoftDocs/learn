Suppose you're a developer who works for a medical-transcription company. Your company's clients are a team of doctors who record their notes as audio files on handheld digital voice recorders. They share their files with your company through a shared cloud drive, and their notes are a combination of brief memos and longer dictations.

Your company has to maintain a large staff of transcribers, and these two types of audio files present interesting challenges for your company:

- Your company's transcribers require a great deal of time to process the volume of brief memos from your clients, so it's difficult for your company to return the transcriptions within the timeframe that's defined in your company's service-level agreement (SLA).

- The longer dictations often can't be transcribed in a single session, and your company's transcribers have difficultly remembering where they left off during their previous session.

You've heard that Microsoft's Azure Cognitive Services provide developers with APIs to create applications that take advantage of Azure's speech-to-text features, and your manager has asked you to research how you can use Azure Cognitive Services' speech-to-text features to create an application you can use to offset some of the transcription tasks, thereby alleviating some of your operating costs and service-level agreement issues.

In this module, you'll learn how to use Azure Cognitive Services to create a speech-to-text application that converts a sample WAVE file into text.

## Learning objectives

In this module, you'll:

- Create an Azure Cognitive Services account.
- Create a command-line application that uses single-shot recognition to convert speech to text.
- Create a command-line application that uses continuous recognition to convert speech to text.

## Prerequisites

- Basic familiarity with development tools
