Now we'll consider whether Azure Data Lake Storage is the right choice for your organization's big data requirements. Your organization wants to control the costs of big data storage, especially the hardware and software expenditures associated with huge data volumes. Management wants to store every data type generated by your organization. It's especially keen to remove all data silos that keep data sources separate. Your organization's management wants to make it easier to generate business insights from any data. They also want the ability to run analytics workloads on real-time data streams.

## Decision criteria

If your organization stores big data, it most likely uses a data warehouse. Administrators and data engineers know that traditional data warehouses:

- Have limits on how much data they can store.
- Aren't designed to store every type of data.
- Aren't designed to store all available data.
- Don't work well with high-velocity data.

These issues are irrelevant if your organization has:

- Relatively small datasets.
- A single type of data.
- Subsets of your total data.
- Data that comes in slowly.

To help you decide whether Azure Data Lake Storage is a good fit for your organization, let's review the decision criteria in more detail. Some of the criteria indicating whether Azure Data Lake Storage will meet your performance and functional goals are:

- Data size
- Data diversity
- Data completeness
- Data velocity

### Data size

When deciding whether to move from a traditional, on-premises data warehouse to a data lake, one of the biggest factors is data size. Here, data size refers to both the overall amount of stored data and the size of individual files.

Data warehouses are purpose-built for managing large volumes of data. But there are hard limits on the total amount of data they can manage:

- They use costly, high-end hardware for reliability and performance.
- Expansion is limited to the physical footprint of the data center.
- Their overall costs grow with data volume.
- They have ongoing costs for data center expenses such as cooling and security.

In comparison, Azure Data Lake Storage:

- Runs on virtual hardware on the Azure platform, making storage scalable, fast, and reliable without incurring massive charges.
- Separates storage costs from compute costs. As your data volume grows, only your storage requirements change.
- Takes care of all costs associated with the data center.

### Data diversity

Is Azure Data Lake Storage a better choice when managing a diverse collection of data types? First, let's review some of the reasons a traditional data warehouse might not be the best choice for diverse data. Data warehouses:

- Often have expensive and complicated configurations that only support certain data types.
- Rarely store raw data.
- Exclude data that's incompatible with the warehouse configuration.
- Often aren't configured for real-time data that comes in multiple formats&mdash;for example, JSON files, log files, and CSV files.
- Tend to store only those data types that are required by business analysts.

Azure Data Lake Storage overcomes these data access barriers, thereby enabling so-called *data democratization* where data is accessible to all users, not just users with technical knowledge. It overcomes barriers by enabling your organization to store all your data formats (including raw data) in a single location. Eliminating data silos enables users to use a tool such as Azure Data Explorer to access and work with every data item in their storage account.

### Data completeness

Does Azure Data Lake Storage facilitate the storage of complete datasets? Traditional data warehouses aren't designed to store every piece of data generated by the organization:

- When an organization's incoming data is processed, much of the data is either incompatible with this processing or is lost.
- To control costs, stored data is almost always a subset of the total data.
- Data warehouses have policies that delete or archive old data, making it difficult to access.

Let's review how Azure Data Lake Storage compares to data warehouses. Azure Data Lake Storage:

- Doesn't process data at all during ingestion, so all data is compatible, and none is lost.
- Stores all the available data, whether it's raw, semi-structured, or structured.
- Doesn't require deleting or archiving of old data.

### Data velocity

Is Azure Data Lake Storage a suitable choice for real-time data ingestion and storage?

Traditional data warehouses usually aren't ideal for managing high-speed, streaming data, because:

- Most data warehouses are configured for *batch input*, where the data is ingested in discrete transactions rather than in real time.
- The schema-on-read approach used by data warehouses is expensive and slow when applied to the high velocity of incoming streaming data.
- Data warehouses work best with structured data, but streaming data is often in a semi-structured format such as JSON.
- Data warehouses filter incoming data, but the analytics workloads for streaming data require access to the complete dataset.

By contrast, Azure Data Lake Storage was built with real-time data in mind. Azure Data Lake Storage:

- Can ingest real-time data directly from an instance of Azure IoT Hub, Azure Event Hubs, or Azure Stream Analytics.
- Doesn't apply a schema during ingestion, so there's no incoming bottleneck for real-time data.
- Works with semi-structured data.
- Lets you ingest all your real-time data into your storage account.

Azure Data Lake Storage also enables you to output the ingested streaming data to various Azure services, such as Azure Machine Learning and Azure Synapse Analytics.

## Apply the criteria

To decide whether Azure Data Lake Storage is a suitable solution for your organization, review the following use cases and recommendations.

### Should you use Azure Data Lake Storage to lower costs?

Organizations might not save much money by moving from a data warehouse to Azure Data Lake Storage if they have:

- Relatively small amounts of data.
- Data that's generated or modified relatively slowly.

However, you should consider using Azure Data Lake Storage to reduce total cost of ownership (TCO) if your organization:

- Generates massive amounts of data.
- Generates new data quickly.
- Makes frequent changes to the data configuration.
- Incurs costs for hardware, software, and maintenance that takes up a significant and increasing portion of your IT budget.

For example, a national package delivery business generates large amounts of structured and real-time data. As a result, data costs are a major concern. Azure Data Lake Storage would be a good fit to achieve the organization's goal of controlling data costs.

### Should you use Azure Data Lake Storage to improve data access?

Organizations might not require the improved data access that comes from moving to Azure Data Lake Storage if they:

- Want to tightly control how users access data.
- Don't need to store raw and semi-structured data.

However, you should consider using Azure Data Lake Storage to enhance data democratization if your organization:

- Wants to prevent data silos that occur when separate datasets can't be queried or integrated.
- Wants to give users access to all your organization's data.
- Wants to give users more flexibility in the tools they use to access the data.

The package delivery business is likely riddled with data silos because it has many different departments that generate their own large datasets. Azure Data Lake Storage would eliminate those data silos and increase access to all the organization's data.

### Should you use Azure Data Lake Storage for data insights?

Using Azure Data Lake Storage for data insights might not be suitable for organizations that:

- Have a narrow scope of what they want to study when analyzing data.
- Employ business professionals to analyze most of the data.

However, you should consider using Azure Data Lake Storage for data insights if your organization:

- Wants to offer users a more flexible approach to exploring the data.
- Wants to give analysts access to both raw and semi-structured data.
- Wants to enable users to use any or all available data for building models and sandboxes.

The package delivery business is a competitive industry that requires innovation and speed, which requires business insight. Azure Data Lake Storage would be a good fit for generating those insights by giving analysts access to all the company's data.

### Should you use Azure Data Lake Storage for real-time analysis?

You don't need Azure Data Lake Storage to handle real-time data if:

- Your organization's streaming data has a relatively slow velocity and comes in a single data format (such as JSON files).
- Your data warehouse is configured to handle that data format by applying any processing.

However, you should consider using Azure Data Lake Storage for real-time analytics if your organization:

- Ingests streaming data that come in quickly.
- Ingests real-time data that arrives in multiple data formats.
- Wants to apply multiple types of analytics workloads to the data, such as machine learning, model prediction, and sentiment analysis.

The package delivery business generates real-time data courtesy of the delivery truck IoT sensors, the dash cam video feeds, and the web server logs. Therefore, Azure Data Lake Storage is an ideal choice to run analytics workloads on the package delivery business' real-time data streams.
