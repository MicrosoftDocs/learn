{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision. Images as Tensors\n",
    "\n",
    "Computer Vision (CV) is a field that studies how computers can gain some degree of understanding from digital images and/or video. *Understanding* in this definition has a rather broad meaning - it can range from being able to distinguish between a cat and a dog on the picture, to more complex tasks such as describing the image in natural language.\n",
    "\n",
    "The most common problems of computer vision include:\n",
    "\n",
    "* **Image Classification** is the simplest task, when we need to classify an image into one of many pre-defined categories, for example, distinguish a cat from a dog on a photograph, or recognize a handwritten digit.\n",
    "\n",
    "* **Object Detection** is a bit more difficult task, in which we need to find known objects on the picture and localize them, that is, return the **bounding box** for each of recognized objects.\n",
    "\n",
    "* **Segmentation** is similar to object detection, but instead of giving bounding box we need to return an exact pixel map outlining each of the recognized objects.  \n",
    "\n",
    "![An image showing how computer vision object detection can be performed with cats, dogs, and ducks.](images/2-image-data-1.png)\n",
    "\n",
    "Image taken from [CS224d Stanford Course](https://cs224d.stanford.edu/index.html)\n",
    "\n",
    "We’ll focus on **image classification** task, and how neural networks can be used to solve it. As with any other machine learning tasks, to train a model for classifying images we’ll need a labeled dataset, that is, a large number of images for each of the classes. \n",
    "\n",
    "\n",
    "## Images as Tensors\n",
    "\n",
    "Computer Vision works with Images. As you probably know, images consist of pixels, so they can be thought of as a rectangular collection (array) of pixels.\n",
    "\n",
    "In the first part of this tutorial, we will deal with handwritten digit recognition. We will use the MNIST dataset, which consists of grayscale images of handwritten digits, 28x28 pixels. Each image can be represented as 28x28 array, and elements of this array would denote intensity of corresponding pixel - either in the scale of range 0 to 1 (in which case floating point numbers are used), or 0 to 255 (integers). A popular python library called `numpy` is often used with computer vision tasks, because it allows to operate with multidimensional arrays effectively.\n",
    "\n",
    "To deal with color images, we need some way to represent colors. In most cases, we represent each pixel by 3 intensity values, corresponding to Red (R), Green (G) and Blue (B) components. This color encoding is called RGB, and thus color image of size $W\\times H$ will be represented as an array of size $3\\times H\\times W$ (sometimes the order of components might be different, but the idea is the same).\n",
    "\n",
    "![Grayscale Image](images/2-image-data-2.png) | ![RGB Image](images/2-image-data-3.png)\n",
    "------|------\n",
    "5x5 Grayscale Image | 5x5 Color (RGB) Image\n",
    "\n",
    "Using multi-dimensional arrays to represent images also has an advantage, because we can use an extra dimension to store a sequence of images. For example, to represent a video fragment consisting of 200 frames with 800x600 dimension, we may use the tensor of size 200x3x600x800.\n",
    "\n",
    "Multi-dimensional arrays are also called **tensors**. Usually, we refer to tensors when we speak about some neural network framework, such as PyTorch. The main difference between tensors in PyTorch and numpy arrays is that tensors support parallel operations on GPU, if it is available. Also, PyTorch offers additional functionality, such as automatic differentiation, when operating on tensors.  \n",
    "\n",
    "## Import packages and load the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/computer-vision-pytorch/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "#Import the packages needed.\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch has a [number of datasets](https://pytorch.org/vision/stable/datasets.html) available right from the library. Here we are using the well-known [MNIST](http://yann.lecun.com/exdb/mnist/) dataset of handwritten digits, available through `torchvison.datasets.MNIST` in PyTorch. The dataset object returns the data in the form of Python Imagine Library (PIL) images, which we convert to tensors by passing a `transform=ToTensor()` parameter. \n",
    "\n",
    "When using your own notebooks, you can also experiment with the other built in datasets, in particular [FashionMNIST](https://pytorch.org/vision/stable/datasets.html#fashion-mnist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "data_train = torchvision.datasets.MNIST('./data',\n",
    "        download=True,train=True,transform=ToTensor())\n",
    "data_test = torchvision.datasets.MNIST('./data',\n",
    "        download=True,train=False,transform=ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the dataset\n",
    "Now that we have downloaded the dataset we can visualize some of the digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1,7)\n",
    "for i in range(7):\n",
    "    ax[i].imshow(data_train[i][0].view(28,28))\n",
    "    ax[i].set_title(data_train[i][1])\n",
    "    ax[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset structure\n",
    "\n",
    "We have a total of 6000 training images and 1000 testing images. Its important to split out the data for training and testing. We also want to do some data exploration to get a better idea of what our data looks like\n",
    "\n",
    "Each sample is a tuple in the following structure:\n",
    " * First element is the actual image of a digit, represented by a tensor of shape 1x28x28\n",
    " * Second element is a **label** that specifies which digit is represented by the tensor. It is a tensor that contains a number from 0 to 9.\n",
    "\n",
    "`data_train` is a training dataset that we will use to train our model on. `data_test` is a smaller test dataset that we can use to verify our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 60000\n",
      "Test samples: 10000\n",
      "Tensor size: torch.Size([1, 28, 28])\n",
      "First 10 digits are: [5, 0, 4, 1, 9, 2, 1, 3, 1, 4]\n"
     ]
    }
   ],
   "source": [
    "print('Training samples:',len(data_train))\n",
    "print('Test samples:',len(data_test))\n",
    "\n",
    "print('Tensor size:',data_train[0][0].size())\n",
    "print('First 10 digits are:', [data_train[i][1] for i in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All pixel intensities of the images are represented by floating-point values in between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min intensity value:  0.0\n",
      "Max intensity value:  1.0\n"
     ]
    }
   ],
   "source": [
    "print('Min intensity value: ',data_train[0][0].min().item())\n",
    "print('Max intensity value: ',data_train[0][0].max().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading your own images\n",
    "\n",
    "In most of the practical applications, you would have your own images located on disk that you want to use to train your neural network. In this case, you need to load them into PyTorch tensors. \n",
    "\n",
    "One of the ways to do that is to use one of the Python libraries for image manipulation, such as *Open CV*, or *PIL/Pillow*, or *imageio*. Once you load your image into numpy array, you can easily convert it to tensors. \n",
    "\n",
    "> It is important to make sure that all values are scaled to the range [0..1] before you pass them to a neural network - it is the usual convention for data preparation, and all default weight initializations in neural networks are designed to work with this range. `ToTensor` transform that we have seen above automatically scales PIL/numpy images with integer pixel values into [0..1] range.\n",
    "\n",
    "Even better approach is to use functionality in **Torchvision** library, namely `ImageFolder`. It does all the preprocessing steps automatically, and also assigns labels to images according to the directory structure. We will see the example of using `ImageFolder` later in this course, once we start classifying our own cats and dogs images.\n",
    "\n",
    "> It is important to note that all images should be scaled to the same size. If your original images have different aspect ratios, you need to decide how to handle this scaling - either by cropping images, or by padding extra space.\n",
    "\n",
    "## Takeaway\n",
    "\n",
    "Neural networks work with tensors, and before training any models we need to convert our dataset into a set of tensors. This will often require rWe have loaded training and test datasets, and we are ready to start training our first neural network!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "86193a1ab0ba47eac1c69c1756090baa3b420b3eea7d4aafab8b85f8b312f0c5"
  },
  "kernelspec": {
   "display_name": "py38_default",
   "language": "python",
   "name": "conda-env-py38_default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
