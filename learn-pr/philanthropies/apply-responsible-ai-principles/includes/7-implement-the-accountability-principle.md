The Accountability principle states that AI systems and the AI developers should be responsible for how their AI systems operate. The people who manage the AI systems should continuously monitor system performance and mitigate risks. Here are some key points to keep in mind to ensure that the AI systems you use are accountable:

:::image type="icon" source="../media/implement-accountability-principle.png":::

**Human oversight**. AI systems should be monitored to ensure responsible outcomes. For example, you should have learning content moderators and policy teams to oversee your AI system's recommendations to learners.

**Auditability**. AI systems should have capabilities that allow third parties to review their operations, recommendations, and performance data. For example, an AI grading tool should have APIs and logs allowing supervisors to audit candidate scores for systemic and societal biases.

**Controls**. AI systems should have measures in place that give you control over the system when needed. For example, a moderation algorithm should have controls allowing you to intervene if the AI system produces inaccurate outputs.

## Purpose of ensuring the accountability of AI systems

Accountability is a vital principle in the advancement of responsible AI.  It serves several important purposes, including:

- **Transparency**. Accountability supports explainability by requiring that developers inspect and understand their systems' decision-making processes. This sheds light on how AI systems determine outputs and recommendations.

- **Fairness**. Accountability enables the evaluation of the equitable treatment of different learner groups and the correction of issues of discrimination or exclusion.

- **Reliability & safety**. Accountability allows for the mitigation of unintentional harm through controls that can remedy unsafe system operations.

- **Trust**. Accountability builds public confidence that AI systems can operate reliably as intended and that AI creators can swiftly address unexpected problems.

- **Improvement**. Accountability provides diagnostic data to continuously enhance system performance, avoid unintended consequences, and address technical limitations.

## Setting up accountable AI systems

By ensuring that you are accountable for the AI systems you use, you can help promote trust, transparency, fairness, reliability & safety, and responsibility in using AI. As the person who implements an AI system, you are accountable for how the system operates. You should draw upon industry standards to develop accountability standards. These standards can ensure that AI systems are not the final authority on any decision that impacts people's lives. They also ensure that you have meaningful control over otherwise highly autonomous AI systems.

To ensure accountability in your AI system, you should:

- Set up internal review boards to observe and provide guidance on the responsible implementation of AI systems. The boards can also help with tasks like defining best practices for documenting and testing AI systems during implementation or providing guidance for sensitive cases.

- Ensure your team is trained to use and maintain the AI system responsibly and understand when the system may require extra technical support.

- Keep subject matter experts in the loop by reporting to them and involving them in decisions about AI system implementation. When automation of decisions is required, ensure that subject matter experts can inspect, identify, and resolve challenges with the AI system's output and execution.

- Put in place a clear system of governance to conduct remediation or correction activities if AI models start operating in an unfair or potentially harmful manner.

The accountability principle in AI helps ensure that AI systems are developed and managed responsibly. It involves continuous monitoring, human oversight, auditability, and control measures to maintain transparency, fairness, reliability, safety, and trust. By setting up accountable AI systems, developers and managers can foster public confidence, mitigate risks, and improve system performance, ultimately leading to more ethical and effective AI solutions. Remember, accountability is not just a guideline but a commitment to responsible AI implementation and governance.
