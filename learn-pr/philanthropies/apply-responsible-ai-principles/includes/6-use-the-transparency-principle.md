Transparency is an important principle in ethical AI. It supports other AI principles, including:

:::image type="icon" source="../media/use-transparency-principle.png":::

**Accountability:** Allows oversight organizations to check algorithms for problems, assess how well the system works, and determine who is accountable.

**Fairness:** Prevents unfair discrimination by requiring systems to validate their decisions and demonstrate fair treatment of different groups.

Transparency emphasizes the importance of making AI systems easy to understand. Making AI systems easier to understand involves creators explaining how their AI systems work, why they work that way, and being honest about capabilities and limitations. Achieving transparency builds trust, especially as AI becomes more integrated into our daily lives. Transparency means:

**Explicability:** Creators of AI systems should provide clear explanations of how the system functions and makes choices. Technical details and corporate secrecy shouldn't obscure these processes. For instance, a virtual assistant should openly explain how it processes voice commands and what it does with that information to carry out tasks. Openness makes it easier for people to trust and make sense of AI systems.

**Justification:** It's important for the creators of AI systems to be able to explain why they designed them the way they did. For example, in the context of a recommendation system on a streaming platform, it should be able to clarify why it suggests specific movies or songs. For instance, it might mention that it recommended a particular song based on the user's listening history. Transparency helps comprehending and having confidence in the system.

**Honesty:** AI creators should provide transparent information regarding their system's capabilities and limitations. When users consider a health monitoring app, the app's creator should be truthful about what it can and can't do. For example, if the app isn't accurate in measuring certain health parameters, it should openly acknowledge these limitations. Transparency empowers individuals to make informed decisions.

**Auditability:** AI systems should possess logging, reporting, and auditing capabilities to monitor their operations, identify errors, detect biases, and facilitate oversight. Let's take a credit scoring AI system as an example. It should keep a record of how it evaluates creditworthiness and the factors it considers. Records enable auditors to review its decisions and ensure fairness and accuracy in assessing individuals' credit. Practice helps confirm that AI systems are functioning responsibly.

## Ensuring transparency in AI

By ensuring that the AI systems you use are transparent, you can better understand how they work and generate informed decisions. Transparency can help you promote trust, accountability, fairness, safety, and inclusiveness while using AI in education. Here are some key points to ensure transparency in the AI systems you use:

- Look for systems accompanied by documentation of characteristics of their datasets to help developers understand if a specific dataset is appropriate for their use case.

- Ensure that employees who interpret the output from AI are trained in how to do so and remain accountable for making consequential decisions based on the results.

:::image type="icon" source="../media/ensuring-transparency-in-ai.png":::

Grasping the essence of transparency in AI is merely the first step. As we move beyond transparency, it's essential to understand that this is deeply connected with accountability. These elements aren't standalone; they're connected. In the next unit, you explore the principle of accountability. You examine how this principle is crucial to ensuring that AI systems are transparent, and adhere to the highest standards of ethical responsibility in every situation.
