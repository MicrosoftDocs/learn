Reliability & safety in AI tools are crucial because they ensure that the AI tools operate as intended, respond appropriately to unexpected situations, resist malicious manipulation, and provide consistent, trustworthy outcomes. In this video, you will learn about the importance of reliability and safety in AI tools, including the qualities of resiliency and availability.

> [!VIDEO https://learn-video.azurefd.net/vod/player?id=3f3edc00-d374-4c4e-84c7-d1aef07e247f]

To build trust in AI, systems must be reliable and secure, able to handle unexpected situations, and avoid manipulation. As you learned in the video, reliability means the system can recover from issues (resilience) and is always available for users. Safety is critical; without it, there could be consequences for everyone involved. To ensure AI systems are reliable and safe, they should be thoroughly tested and follow best practices. Let's look at some of steps that you can follow to make sure an AI system is reliable and safe.

## Ensuring reliability and safety in education

As an educator or trainer using AI systems, you can take steps to ensure the reliability and safety of the AI tools you use. Here are some key points to keep in mind:

**Look for AI systems that have processes** in place for auditing the AI system's performance and verifying that data is being processed as intended. This can help to ensure that the system is operating reliably and safely.

**Choose AI systems that provide detailed explanations** of their operation, including information about design specifications, training data, potential inadequacies of the training data, and the inferences and predictions the AI system generates. This can help you understand how the system makes decisions and uses your learner data.

**Look for AI systems that involve domain experts** in the design and implementation, especially when the system is being used to generate consequential decisions about people. This can help ensure that the system is generating informed and fair predictions.

**Consider using AI systems that have undergone rigorous testing** to ensure that they can respond safely to unanticipated circumstances and don't have unexpected performance failures. This is especially important for AI systems involved in high-stakes scenarios that affect your learners' opportunities.

**Look for AI systems designed to transfer control to a human** during critical situations, decisions that have a high impact, or when the AI system needs further oversight.

**Look for AI systems with robust feedback mechanisms** for your learners to report performance issues so that you can resolve those issues quickly.

When adding AI to educational settings, it's key to choosing systems that can be thoroughly evaluated and handle data properly. Look for AI that's transparent about how it works, uses data, and makes decisions. Having experts involved in creating the AI ensures it makes smart, fair choices. Use AI that's tested for safety in unexpected situations and allows for human oversight when needed. Make sure there's a way for users to quickly report any problems. Following these steps will help you use AI that's safe, trustworthy, will enhance your learning environment.

:::image type="icon" source="../media/look-for-ai-systems-robust-feedback-mechanisms.png":::

Having grasped the principle of reliability and safety, you are now ready to explore the next principle: privacy and security. These principles are not merely supplementary; they are foundational to the integrity of a robust AI framework. In unit 3, you will examine the mechanisms that safeguard sensitive information and protect against unauthorized access. This transition underscores the importance of a holistic approach to AI ethics, where protecting individual rights and maintaining public trust are paramount. By ensuring that AI systems are not only fair and reliable but also private and secure, we can foster an environment of confidence and dependability in the technology that shapes our future.
