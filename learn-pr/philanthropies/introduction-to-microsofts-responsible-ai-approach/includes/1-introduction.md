As AI becomes more deeply woven into our everyday routines, Microsoft is leading the charge to ensure AI is developed and deployed responsibly. Microsoft recognizes the need for responsible AI systems, and has created frameworks to help people build and recognize responsible AI systems. These measures ensure that AI technologies aren't just cutting-edge and efficient, but also align with our fundamental values.

Consider Microsoft Copilot. Microsoft Copilot is designed as an AI assistant to provide information, answer questions, and engage in conversations. This tool sets clear expectations by informing users of its capabilities and limitations. It maintains relevance by understanding and responding to user inputs, manages errors by identifying and correcting them, and improves through adaptive learning from user feedback. The system is impartial to all users, ensuring reliability and safety with accurate information. It upholds privacy by not retaining personal data and secures user information. Accessible to everyone, it promotes inclusivity, operates with transparency by clarifying its functions, and demonstrates accountability by rectifying mistakes.

In this module, you receive an overview of Microsoft's commitment to developing guidelines and standard requirements for AI systems, which are based on six core principles: fairness, reliability and safety, privacy and security, inclusiveness, transparency, and accountability. These frameworks are designed to ensure that AI systems are created and implemented successfully, aligning AI technologies with responsible practices.
