Azure IoT Hub is a managed cloud service. It provides secure registration for IoT devices for high-throughput communication from device to the cloud and from the cloud to device. You'll use this resource to register an NVIDIA embedded device and configure it with a DeepStream-based IoT Edge deployment.

To register an NVIDIA embedded device and configure it with an IoT Edge deployment:

1. Complete the steps in the **Create an IoT hub** section of [Quickstart: Create an IoT hub using the Azure portal](/azure/iot-hub/iot-hub-create-through-portal#create-an-iot-hub?azure-portal=true). Steps that are described in other sections of the quickstart are optional.

1. NVIDIA DeepStream supports integration with Azure IoT Edge through [Azure MQTT protocol adapter libraries](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvmsgbroker.html#azure-mqtt-protocol-adapter-libraries?azure-portal=true). The libraries extend the [Gst-nvmsbroker](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_plugin_gst-nvmsgbroker.html#?azure-portal=true) plugin that is part of the DeepStream SDK. Through the Azure protocol adapter, DeepStream applications can publish messages directly to an IoT hub in Azure by using the MQTT protocol.

    Complete the following steps on an x86-based host machine that has the DeepStream 6.0 Graph Composer installed. The steps assume that you've completed the steps described in the previous modules, [Set up and configure an NVIDIA DeepStream development environment](/learn/modules/setup-configure-nvidia-deepstream-development/?azure-portal=true) and [Introduction to NVIDIA DeepStream Graph Composer with Azure](/learn/modules/introduction-nvidia-deepstream-graph-composer-azure/?azure-portal=true).

1. In the DeepStream Graph Composer application, select **File** > **Open Graph**. Go to */opt/nvidia/deepstream/deepstream/reference_graphs/deepstream-test4* and select the *deepstream-test4.yaml* file. Then, select **Okay**.

    :::image type="content" source="../media/composer-open-test4.png" alt-text="Screenshot that shows opening the DeepStream Test4 application in DeepStream Graph Composer." lightbox="../media/composer-open-test4.png":::

    The sample builds on top of the *deepstream-test1* graph used earlier to demonstrate how to send inference output messages to the cloud.

    :::image type="content" source="../media/composer-test4.png" alt-text="Screenshot of the opened DeepStream Test4 application in DeepStream Graph Composer." lightbox="../media/composer-test4.png":::

    The graph contains more `NvDsSampleProbeMessageMetaCreation` and `NvDsMsgConvBroker` components, which work together send messages to the cloud. `NvDsSampleProbeMessageMetaCreation` transforms the metadata that's generated by the pipeline into another metadata of type `NVDS_EVENT_MSG_DATA`. This metadata is serialized by `NvDsMsgConvBroker` and then sent to the cloud via a message broker protocol.

1. To modify this sample to publish to the Azure cloud, update the `msg-conv-config` property of the `NvDsMsgConvBroker` component. Change the property from */opt/nvidia/deepstream/deepstream/lib/libnvds_kafka_proto.so* to */opt/nvidia/deepstream/deepstream/lib/libnvds_azure_edge_proto.so*. This change configures the output to use the Azure protocol adapter that ships with the DeepStream SDK.
