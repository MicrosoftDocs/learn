{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import requests\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Matplotlib is building the font cache; this may take a moment.\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start by including the code that gets the data and model:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "!wget -Nq https://raw.githubusercontent.com/MicrosoftDocs/tensorflow-learning-path/main/intro-tf/tintro.py\n",
        "from tintro import *"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to make a prediction, we need to pass some data to the model, and do a single forward pass through the network to get the prediction. If the code below is unclear to you, make sure you go back to module 1, where we explain it in detail. Remember that, unlike during testing, we don't need to call the loss function because we're no longer interested in evaluating how well the model is doing. Instead, we call `softmax` to convert the values of the output vector into values between 0 and 1, and then get the `argmax` of that vector to get the predicted label index.\n",
        "\n",
        "Similarly to the training and testing sections, once we're done with debugging, we can add a `@tf.function` decorator to get the performance benefits of graph execution."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "@tf.function\n",
        "def predict(model: tf.keras.Model, X: np.ndarray) -> tf.Tensor:\n",
        "  y_prime = model(X, training=False)\n",
        "  probabilities = tf.nn.softmax(y_prime, axis=1)\n",
        "  predicted_indices = tf.math.argmax(input=probabilities, axis=1)\n",
        "  return predicted_indices"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now make a prediction. First we'll get the image we'll use for prediction."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "model = NeuralNetwork()\n",
        "model.load_weights('outputs/weights')\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/MicrosoftDocs/tensorflow-learning-path/main/intro-keras/predict-image.png'\n",
        "\n",
        "with Image.open(requests.get(url, stream=True).raw) as image:\n",
        "  X = np.asarray(image, dtype=np.float32).reshape((-1, 28, 28)) / 255.0\n",
        "\n",
        "plt.figure()\n",
        "plt.axis('off')\n",
        "plt.imshow(X.squeeze(), cmap='gray')\n",
        "plt.show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're now ready to make the prediction by passing the image we read into the `predict` function."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "predicted_index = predict(model, X).numpy()[0]\n",
        "predicted_name = labels_map[predicted_index]\n",
        "\n",
        "print(f'Predicted class: {predicted_name}')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: Ankle Boot\n"
          ]
        }
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "a7d8d32a02de2fe32a77a4e581138922e011c09664b6c2991156e76c4176efab"
    },
    "kernelspec": {
      "name": "conda-env-py37_tensorflow-py",
      "language": "python",
      "display_name": "py37_tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "conda-env-py37_tensorflow-py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}