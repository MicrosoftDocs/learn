{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to image data\r\n",
        "\r\n",
        "In computer vision, we normally solve one of the following problems:\r\n",
        "\r\n",
        "* **Image Classification** is the simplest task, when we need to classify an image into one of many pre-defined categories, for example, distinguish a cat from a dog on a photograph, or recognize a handwritten digit.\r\n",
        "\r\n",
        "* **Object Detection** is a bit more difficult task, in which we need to find known objects on the picture and localize them, i.e. return the **bounding box** for each of recognized objects.\r\n",
        "\r\n",
        "* **Segmentation** is similar to object detection, but instead of giving bounding box we need to return an exact pixel map outlining each of the recognized objects.  \r\n",
        "\r\n",
        "![An image showing how computer vision object detection can be performed with cats, dogs, and ducks.](https://i.stack.imgur.com/mFBCV.png)\r\n",
        "\r\n",
        "Image taken from [CS224d Stanford Course](https://cs224d.stanford.edu/index.html)\r\n",
        "\r\n",
        "## Images as Tensors\r\n",
        "\r\n",
        "Computer Vision works with Images. As you probably know, images consist of pixels, so they can be thought of as a rectangular collection (array) of pixels.\r\n",
        "\r\n",
        "In the first part of this tutorial, we will deal with handwritten digit recognition. We will use the MNIST dataset, which consists of grayscale images of handwritten digits, 28x28 pixels. Each image can be represented as 28x28 array, and elements of this array would denote intensity of corresponding pixel - either in the scale of range 0 to 1 (in which case floating point numbers are used), or 0 to 255 (integers). A popular python library called `numpy` is often used with computer vision tasks, because it allows to operate with multidimensional arrays effectively.\r\n",
        "\r\n",
        "To deal with color images, we need some way to represent colors. In most cases, we represent each pixel by 3 intensity values, corresponding to Red (R), Green (G) and Blue (B) components. This color encoding is called RGB, and thus color image of size $W\\times H$ will be represented as an array of size $H\\times W\\times 3$ (sometimes the order of components might be different, but the idea is the same).\r\n",
        "\r\n",
        "Multi-dimensional arrays are also called **tensors**. Using tensors to represent images also has an advantage, because we can use an extra dimension to store a sequence of images. For example, to represent a video fragment consisting of 200 frames with 800x600 dimension, we may use the tensor of size 200x600x800x3.\r\n",
        "\r\n",
        "## TensorFlow and Keras versions\r\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "#Import the packages needed.\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "\r\n",
        "print(tf.__version__)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.0\n"
          ]
        }
      ],
      "metadata": {
        "tags": []
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow is now at version 2, and it differs significantly between versions 1 and 2. Thus it is important to check that we have correct version, otherwise the code is likely not to work.\r\n",
        "\r\n",
        "In version 2 TensorFlow added a higher-level neural network construction API called [**Keras**](http://keras.io). With Keras, most model building steps can be done in a much simpler way. This has made Keras a preferred way to start training deep learning networks. Only switching to pure TensorFlow when you need to develop some custom architectures for research or more complex scenarios. Since Keras is part of TensorFlow, the terms are used interchangeably and many times when someone says TensorFlow they are actually talking about the Keras.\r\n",
        "\r\n",
        "In this tutorial, we will focused on developing neural networks using **Keras** in **TensorFlow 2**.\r\n",
        "\r\n",
        "## Loading the MNIST Dataset\r\n",
        "\r\n",
        "Keras has a [number of datasets](https://www.TensorFlow.org/api_docs/python/tf/keras/datasets) available right from the library. Here we are using the well-known [MNIST](http://yann.lecun.com/exdb/mnist/) dataset of handwritten digits, available through `tf.keras.datasets.mnist`. It has a function `load_data()` that returns train and test MNIST datasets.\r\n",
        "\r\n",
        "When using your own notebooks, you can experiment with the other built in datasets, in particular [FashionMNIST](https://www.TensorFlow.org/api_docs/python/tf/keras/datasets/fashion_mnist). It has exactly the same shape as MNIST, but contains outlines of different clothing types. You should be able to experiment with FashionMNIST by simply replacing the dataset name below.\r\n",
        "\r\n",
        "> **Note**: When running this sample code locally, data would automatically be downloaded, you can just call `load_data()` without parameters. For the sandbox environment, we need to pre-fetch the data locally in advance, before calling `load_data`. If you are running on a local notebook, you can ignore the next cell:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "# Pre-fetch the data for the Learn Module\r\n",
        "!mkdir -p ~/.keras/datasets\r\n",
        "!wget -P ~/.keras/datasets -q https://github.com/MicrosoftDocs/tensorflowfundamentals/raw/main/data/mnist.npz"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "(x_train,y_train),(x_test,y_test) = keras.datasets.mnist.load_data()\r\n",
        "\r\n",
        "print(x_train.shape, y_train.shape)\r\n",
        "print(x_test.shape,y_test.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (60000,)\n",
            "(10000, 28, 28) (10000,)\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the digits dataset\n",
        "Now that we have downloaded the dataset we can visualize some of the digits"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "fig,ax = plt.subplots(1,7)\r\n",
        "for i in range(7):\r\n",
        "    ax[i].imshow(x_train[i])\r\n",
        "    ax[i].set_title(y_train[i])\r\n",
        "    ax[i].axis('off')"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 7 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset structure\r\n",
        "\r\n",
        "We have a total of 60000 training images (stored in `x_train`) and 10000 testing images (in `x_test`). Labels corresponding to those images are contained in `y_train` and `y_test` accordingly."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "print('Training samples:',len(x_train))\r\n",
        "print('Test samples:',len(x_test))\r\n",
        "\r\n",
        "print('Tensor size:',x_train[0].shape)\r\n",
        "print('First 10 digits are:', y_train[:10])\r\n",
        "print('Type of data is ',type(x_train))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 60000\n",
            "Test samples: 10000\n",
            "Tensor size: (28, 28)\n",
            "First 10 digits are: [5 0 4 1 9 2 1 3 1 4]\n",
            "Type of data is  <class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the type of data is numpy array, which allows us to manipulate it using any numpy operations. All pixels of the images are represented by integer numbers from 0 to 255:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "source": [
        "print('Min intensity value: ',x_train.min())\r\n",
        "print('Max intensity value: ',x_train.max())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min intensity value:  0\n",
            "Max intensity value:  255\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reason it is between 0 and 255 is because of how color is represented in a binary format. RGB (red, green, blue) are each represented as a 0-255 value to create digital colors.  If we load any image from file using [OpenCV](https://opencv.org/) or [PIL](https://pillow.readthedocs.io/en/stable/) you will end up having numpy array with pixel intensities in the same range [0..255].\r\n",
        "\r\n",
        "> Note: If you are loading color image, the shape of the array would be slightly different, each pixel contains 3 color values (R,G and B). Thus the image 300x300 pixels will be represented by 300x300x3 numpy array.\r\n",
        "\r\n",
        "If we want to feed our images to the neural network, it is important to make sure that all values are scaled to the range [**0 - 1**] before we start training. So, we will rescale the dataset in order to have all values in the required normalized range:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "source": [
        "x_train = x_train.astype(np.float32)/255.0\r\n",
        "x_test = x_test.astype(np.float32)/255.0"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have the data, and we are ready to start training our first neural network!"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "86193a1ab0ba47eac1c69c1756090baa3b420b3eea7d4aafab8b85f8b312f0c5"
    },
    "kernelspec": {
      "display_name": "py37_tensorflow",
      "language": "python",
      "name": "conda-env-py37_tensorflow-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}