{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**NOTE** \n",
        "- If the kernel doesn't autoselect when you run the code, choose *azureml_py38* from the dropdown menu.\n",
        "- You might get an error message that no GPU or CUDA-capable device was found. However, the code should still run successfully using CPU resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import gzip\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's start by getting familiar with the data you'll be using, the Fashion MNIST dataset. This dataset contains 70,000 grayscale images of articles of clothing: 60,000 images for training and 10,000 for testing. The images are square and contain 28 &times; 28 = 784 pixels, where each pixel is represented by a value between 0 and 255. Each of these images is associated with a label, which is an integer between 0 and 9 that classifies the article of clothing. The following dictionary helps us understand the clothing categories corresponding to these integer labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels_map = {\n",
        "  0: 'T-Shirt',\n",
        "  1: 'Trouser',\n",
        "  2: 'Pullover',\n",
        "  3: 'Dress',\n",
        "  4: 'Coat',\n",
        "  5: 'Sandal',\n",
        "  6: 'Shirt',\n",
        "  7: 'Sneaker',\n",
        "  8: 'Bag',\n",
        "  9: 'Ankle Boot',\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you're following this code but executing it outside of this Microsoft Learn sandbox notebook environment, you can load Fashion MNIST by calling the [load_data()](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist/load_data) method of the Fashion MNIST dataset in the Keras API, as you can see in the commented out code below. Keras provides an easy way to get not only Fashion MNIST, but many other popular datasets through [tk.keras.datasets](https://www.tensorflow.org/api_docs/python/tf/keras/datasets). This Learn sandbox notebook already has the data locally, so you can load it directly instead, and create four NumPy arrays containing the training and test data and labels. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (training_images, training_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "def read_images(path: str, image_size: int, num_items: int) -> np.ndarray:\n",
        "  with gzip.open(path, 'rb') as file:\n",
        "    data = np.frombuffer(file.read(), np.uint8, offset=16)\n",
        "    data = data.reshape(num_items, image_size, image_size)\n",
        "  return data\n",
        "\n",
        "def read_labels(path: str, num_items: int) -> np.ndarray:\n",
        "  with gzip.open(path, 'rb') as file:\n",
        "    data = np.frombuffer(file.read(num_items + 8), np.uint8, offset=8)\n",
        "    data = data.astype(np.int64)\n",
        "  return data\n",
        "\n",
        "image_size = 28\n",
        "num_train = 60000\n",
        "num_test = 10000\n",
        "\n",
        "training_images = read_images('data/FashionMNIST/raw/train-images-idx3-ubyte.gz', image_size, num_train)\n",
        "test_images = read_images('data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz', image_size, num_test)\n",
        "training_labels = read_labels('data/FashionMNIST/raw/train-labels-idx1-ubyte.gz', num_train)\n",
        "test_labels = read_labels('data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz', num_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that you have the data, you can display a sampling of images and corresponding labels from the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols = 3\n",
        "rows = 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "  sample_idx = random.randint(0, len(training_images))\n",
        "  image = training_images[sample_idx]\n",
        "  label = training_labels[sample_idx]\n",
        "  figure.add_subplot(rows, cols, i)\n",
        "  plt.title(labels_map[label])\n",
        "  plt.axis('off')\n",
        "  plt.imshow(image.squeeze(), cmap='gray')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's inspect the first label in the training data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_labels[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As you saw in the `labels_map` dictionary that you printed earlier, this corresponds to an *Ankle boot*. Now let's inspect the image that corresponds to this label:  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "An image is composed of pixel values, and each pixel in the image is of type unsigned int and contains a value between 0 and 255.\n",
        "\n",
        "For such a small dataset, you could just use the NumPy arrays given by Keras to train the neural network. However, if you had a large dataset, you would need to wrap it in a [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) instance, which handles large data better by making it easy to keep just a portion of it in memory. You can wrap your data in a `Dataset` in this sample, so you're prepared to work with large data in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((training_images, training_labels))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You saw earlier that each pixel of the image is represented by an unsigned int. In machine learning, you generally want the pixel values of your training data to be floating-point numbers between 0 and 1, so you convert them in the following way:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.map(lambda image, label: (float(image) / 255.0, label))\n",
        "test_dataset = test_dataset.map(lambda image, label: (float(image) / 255.0, label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You might have noticed that each value returned by the `Dataset` is a tuple containing an image and a label. You divide each value in the image by 255, and keep the label as is. To see the difference, inspect the values of the same image that you inspected earlier. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset.as_numpy_iterator().next()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, the pixel values are now floating-point numbers between 0 and 1. \n",
        "\n",
        "Now that you have a `Dataset`, you can no longer index it the same way as a NumPy array. Instead, you get an iterator by calling the `as_numpy_iterator` method, and advance it by calling its `next` method. At this point, you have a tuple containing an image and the corresponding label, so you can get the element at index 0 to inspect the image.\n",
        "\n",
        "Finally, tell the `Dataset` to give us batches of data of size 64, and shuffle the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "train_dataset = train_dataset.batch(batch_size).shuffle(500)\n",
        "test_dataset = test_dataset.batch(batch_size).shuffle(500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By specifying the batch size, you're telling the `Dataset` that when you iterate over it, you want to receive not one, but a batch of 64 items instead. If you print the length of the first item returned by the iterator, you can see that you get 64. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(train_dataset.as_numpy_iterator().next()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Why do you want to get batches of 64 when iterating over the `Dataset`? We'll come back to that in the section on training. First you need to learn about the neural network architecture that you'll use for this sample."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "azureml_py38_PT_and_TF"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
