{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import gzip\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's start by getting familiar with the data we'll be using, the Fashion MNIST dataset. This dataset contains 70,000 grayscale images of articles of clothing: 60,000 images for training and 10,000 for testing. The images are square and contain 28 &times; 28 = 784 pixels, where each pixel is represented by a value between 0 and 255. Each of these images is associated with a label, which is an integer between 0 and 9 that classifies the article of clothing. The following dictionary helps us understand the clothing categories corresponding to these integer labels:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels_map = {\n",
        "  0: 'T-Shirt',\n",
        "  1: 'Trouser',\n",
        "  2: 'Pullover',\n",
        "  3: 'Dress',\n",
        "  4: 'Coat',\n",
        "  5: 'Sandal',\n",
        "  6: 'Shirt',\n",
        "  7: 'Sneaker',\n",
        "  8: 'Bag',\n",
        "  9: 'Ankle Boot',\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you're following this code but executing it outside of this Microsoft Learn sandbox notebook environment, you can load Fashion MNIST by calling the [load_data()](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist/load_data) method of the Fashion MNIST dataset in the Keras API, as you can see in the commented out code below. Keras provides an easy way to get not only Fashion MNIST, but many other popular datasets through [tk.keras.datasets](https://www.tensorflow.org/api_docs/python/tf/keras/datasets). This Learn sandbox notebook already has the data locally, so we'll load it directly instead, and create four NumPy arrays containing the training and test data and labels. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (training_images, training_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "def read_images(path: str, image_size: int, num_items: int) -> np.ndarray:\n",
        "  with gzip.open(path, 'rb') as file:\n",
        "    data = np.frombuffer(file.read(), np.uint8, offset=16)\n",
        "    data = data.reshape(num_items, image_size, image_size)\n",
        "  return data\n",
        "\n",
        "def read_labels(path: str, num_items: int) -> np.ndarray:\n",
        "  with gzip.open(path, 'rb') as file:\n",
        "    data = np.frombuffer(file.read(num_items + 8), np.uint8, offset=8)\n",
        "    data = data.astype(np.int64)\n",
        "  return data\n",
        "\n",
        "image_size = 28\n",
        "num_train = 60000\n",
        "num_test = 10000\n",
        "\n",
        "training_images = read_images('data/FashionMNIST/raw/train-images-idx3-ubyte.gz', image_size, num_train)\n",
        "test_images = read_images('data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz', image_size, num_test)\n",
        "training_labels = read_labels('data/FashionMNIST/raw/train-labels-idx1-ubyte.gz', num_train)\n",
        "test_labels = read_labels('data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz', num_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have the data, we can display a sampling of images and corresponding labels from the training data, to get a feel for the data we'll be working with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols = 3\n",
        "rows = 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "  sample_idx = random.randint(0, len(training_images))\n",
        "  image = training_images[sample_idx]\n",
        "  label = training_labels[sample_idx]\n",
        "  figure.add_subplot(rows, cols, i)\n",
        "  plt.title(labels_map[label])\n",
        "  plt.axis('off')\n",
        "  plt.imshow(image.squeeze(), cmap='gray')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's inspect the first label in the training data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_labels[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we saw in the `labels_map` dictionary we printed earlier, this corresponds to an *Ankle boot*. Now let's inspect the image that corresponds to this label:  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_images[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "An image is composed of pixel values, and each pixel in the image is of type unsigned int and contains a value between 0 and 255.\n",
        "\n",
        "For such a small dataset, we could just use the NumPy arrays given to us by Keras to train the neural network. However, if we had a large dataset, we would need to wrap it in a [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) instance, which handles large data better by making it easy to keep just a portion of it in memory. We've decided to wrap our data in a `Dataset` in this sample, so you're prepared to work with large data in the future."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((training_images, training_labels))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You saw earlier that each pixel of the image is represented by an unsigned int. In machine learning, we generally want the pixel values of our training data to be floating-point numbers between 0 and 1, so we convert them in the following way:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.map(lambda image, label: (float(image) / 255.0, label))\n",
        "test_dataset = test_dataset.map(lambda image, label: (float(image) / 255.0, label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You might have noticed that each value returned by the `Dataset` is a tuple containing an image and a label. We divide each value in the image by 255, and we keep the label as is. Let's inspect the values of the same image we inspected earlier, to see the difference. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset.as_numpy_iterator().next()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, the pixel values are now floating-point numbers between 0 and 1. \n",
        "\n",
        "Notice that now that we have a `Dataset`, we can no longer index it the same way as a NumPy array. Instead, we get an iterator by calling the `as_numpy_iterator` method, and we advance it by calling its `next` method. At this point, we have a tuple containing an image and the corresponding label, so we can get the element at index 0 to inspect the image.\n",
        "\n",
        "Finally, we tell the `Dataset` to give us batches of data of size 64, and we shuffle the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "train_dataset = train_dataset.batch(batch_size).shuffle(500)\n",
        "test_dataset = test_dataset.batch(batch_size).shuffle(500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "By specifying the batch size, we're telling the `Dataset` that when we iterate over it, we want to receive not one, but a batch of 64 items instead. If we print the length of the first item returned by the iterator, we'll see that we in fact get 64. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(train_dataset.as_numpy_iterator().next()[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Why do we want to get batches of 64 when iterating over the `Dataset`? We'll come back to that in the section on training. But first we need to learn about the neural network architecture we'll use for this sample."
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "azureml_py38_PT_and_TF"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
