The Semantic Kernel SDK allows you to integrate the power of large language models (LLMs) in your own applications. In the rapidly evolving landscape of artificial intelligence (AI), AI copilots emerged as powerful tools. The Semantic Kernel SDK allows developers to integrate prompts to LLMs and results in their applications, and potentially craft their own copilot-like experiences. 

Suppose you're a developer for Margie's Travel, a global leader in the travel and hospitality industry. You're tasked with creating a personalized AI travel agent. Rather than creating your own language processing model from scratch, you can use the Semantic Kernel to interface with LLMs and create an AI agent that can:

- Understand natural language.
- Provide customized recommendations.
- Book travel accommodations.
- And more!

Whether you're delving into code completion, email composition, or text summarization, Semantic Kernel offers you the ability to harness the capabilities of LLMs like OpenAI, Microsoft Azure OpenAI, and Hugging Face, and effortlessly integrate them into your applications.

This module introduces you to the Semantic Kernel SDK. You can learn how the kernel extends functionality by connecting code to LLMs. You can also learn how the SDK can be used to create artificially intelligent agents that can automate custom tasks.

## Learning objectives

- Understand the purpose of Semantic Kernel.
- Understand prompting basics.
- Learn techniques for more effective prompts.

## Prerequisites

- Experience programming in C#.
- Visual Studio Code IDE installed.
- Familiarity with Azure and the Azure portal.
- Access to Azure Open AI services.