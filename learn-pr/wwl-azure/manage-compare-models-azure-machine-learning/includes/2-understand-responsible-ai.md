As a data scientist, you may train a machine learning model to predict whether someone is able to pay back a loan, or whether a candidate is suitable for a job vacancy. As models are often used when making decisions, it's important that the models are unbiased and transparent.

Whatever you use a model for, you should consider the **Responsible Artificial Intelligence** (**Responsible AI**) principles. Depending on the use case, you may focus on specific principles. Nevertheless, it's a best practice to consider all principles to ensure you're addressing any issues the model may have.

Microsoft has listed six Responsible AI principles:

:::image type="content" source="../media/responsible-ai.png" alt-text="Diagram of interconnected icons surrounding a central globe, representing concepts like fairness, reliability, security, privacy, inclusiveness, transparency, and accountability.":::

- **Fairness**: Ensure your model provides equitable outcomes by testing for and mitigating harmful bias across groups.
- **Reliability & Safety**: Build, test, and monitor your model so it performs consistently, handles edge cases, and prevents unsafe behavior.
- **Privacy & Security**: Protect user data through minimal collection, strong safeguards, and responsible data-handling practices.
- **Inclusiveness**: Design and evaluate systems so people of diverse abilities, backgrounds, and contexts can use them effectively.
- **Transparency**: Communicate clearly how your model works, what data it uses, and how its outputs should be interpreted.
- **Accountability**: Assign human oversight and responsibility so decisions influenced by AI remain traceable and governed.

> [!Tip]
> Learn about the [Responsible AI Standard](https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2022/06/Microsoft-Responsible-AI-Standard-v2-General-Requirements-3.pdf) for building AI systems according to the six key principles.
