Governance policies enforce rules at deployment time, but maintaining compliance requires understanding how data flows through your AI infrastructure after deployment. Consider a scenario where your compliance team receives an audit inquiry: "Which customer records contributed to predictions served by the fraud-detection model during Q3?" Without lineage tracking, answering this question requires manually tracing data flows through storage accounts, transformation pipelines, training jobs, and inference endpoints—a process that takes days and introduces human error. Your audit deadline is 48 hours.

Microsoft Purview's lineage tracking solves this visibility challenge by automatically capturing data flow metadata as information moves through your AI pipelines. Unlike documentation that becomes outdated as pipelines evolve, Purview lineage represents the actual runtime data flows your systems execute. When a data engineer updates a preprocessing script or a data scientist retrains a model with a new dataset, Purview captures those changes automatically. This real-time lineage visibility lets you answer audit questions in minutes instead of days, reducing compliance risk and operational overhead.

## Automated lineage capture for AI workflows

Purview integrates with Azure data services to capture lineage without requiring code changes in your existing pipelines. When you configure Purview to scan Azure Data Factory, Azure Synapse Analytics, and Azure Machine Learning workspaces, these services emit lineage metadata as they execute pipeline activities. For example, when an Azure Data Factory pipeline reads customer transaction records from an Azure SQL database, transforms them using a data flow, and writes the results to Azure Data Lake Storage, Purview captures each step as a lineage relationship. The source database appears as the upstream asset, the data flow as the transformation, and the destination storage as the downstream asset.

:::image type="content" source="../media/automate-lineage-capture-workflows.png" alt-text="Diagram illustrating how Purview integrates with Azure data services to capture lineage without requiring code changes in your existing pipelines.":::

Building on this foundation, Azure Machine Learning contributes more lineage metadata that connects training datasets to models and inference endpoints. When your data scientist registers a dataset in Azure Machine Learning and uses it to train a model, the platform logs this relationship in Purview. The model artifact shows lineage back to the source dataset, including the dataset version used during training. This versioning becomes critical when you need to reproduce predictions for audit purposes—you can trace a specific model prediction back to the exact dataset version that influenced its behavior.

At the same time, Purview captures lineage for model deployment and inference operations. When you deploy a registered model to an Azure Machine Learning managed endpoint or an Azure Kubernetes Service cluster, Purview records the relationship between the model artifact and the endpoint serving predictions. If the endpoint consumes data from a feature store or real-time data stream, those connections appear in the lineage graph as well. This complete view lets you trace data flows from raw source data through preprocessing, training, model deployment, and finally to the business applications consuming AI predictions.

## Lineage visualization and impact analysis

Purview's lineage viewer presents data flows as an interactive graph where nodes represent assets (databases, storage accounts, models, endpoints) and edges represent transformations or data movement. You navigate this graph to understand dependencies: clicking on a training dataset shows all models trained from that data, while clicking on a model reveals which inference endpoints serve it to production applications. This visual representation helps you answer common governance questions quickly: Which models depend on a dataset scheduled for deprecation? Which production applications break if you modify a preprocessing pipeline?

Consider what happens when your data engineering team discovers a data quality issue in customer transaction records from June 15-20. With lineage tracking, you query Purview to identify all downstream assets affected by those records. The lineage graph reveals that the corrupted data flowed into three preprocessing pipelines, contributed to training datasets for two fraud detection models, and influenced predictions served to the payment processing application. This impact analysis lets you scope the incident precisely: you need to retrain two models, redeploy updated endpoints, and notify the payment processing team about potentially unreliable predictions during that five-day window.

This becomes especially important when regulatory audits require evidence of data governance controls. Suppose a privacy regulator asks you to demonstrate that customer personal data in your training datasets receives appropriate protection throughout the AI lifecycle. You use Purview's lineage viewer to generate a report showing data flows from the source customer database (classified as "Confidential - Customer personal data") through preprocessing pipelines (which apply anonymization), into training datasets (stored with encryption), through model training (executed in isolated compute), and finally to inference endpoints (accessed only via private networks). The complete lineage graph serves as audit evidence that your governance controls protect sensitive data at every stage.

## Lineage-driven governance decisions

Lineage metadata enables automated governance workflows that respond to data changes proactively. For example, you can configure alerts that notify data scientists when upstream datasets change classification levels. If a training dataset's sensitivity label upgrades from "Internal Use Only" to "Confidential" due to newly discovered personal data, Purview's lineage tracking identifies all models trained from that dataset. An automated workflow flags those models for security review, requiring data scientists to validate that model access controls match the increased sensitivity level. This automation closes governance gaps that manual processes miss.

:::image type="content" source="../media/impact-analysis-scenario-data-quality.png" alt-text="Diagram showing a source database feeding into an Azure Data Factory pipeline that preprocesses data into a versioned training dataset.":::

Building on this concept, lineage data supports reproducibility requirements for AI model validation. When your model monitoring system detects prediction accuracy degradation, you need to investigate whether data quality issues or model drift caused the problem. Purview's lineage viewer shows the exact dataset versions, preprocessing code versions, and hyperparameter settings used during the original training run. You can reproduce the training environment precisely, retrain the model with identical inputs, and compare results to isolate the root cause—reducing troubleshooting time by 60% compared to manual investigation.

Now that you understand how lineage tracking provides end-to-end visibility into AI data flows, you're ready to apply these concepts hands-on. The next unit guides you through implementing complete governance controls for an AI deployment, combining asset discovery, policy enforcement, and lineage tracking into an integrated governance framework.

:::image type="content" source="../media/data-lineage-captured-purview.png" alt-text="Diagram showing a source database feeding into an Azure Data Factory pipeline that preprocesses data into a versioned training dataset.":::

*End-to-end data lineage captured by Microsoft Purview for an AI pipeline from source data through training to production inference*

