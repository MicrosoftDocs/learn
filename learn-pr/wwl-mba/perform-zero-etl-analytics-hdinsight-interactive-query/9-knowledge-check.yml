### YamlMime:ModuleUnit
uid: learn.wwl.perform-zero-etl-analytics-hdinsight-interactive-query.9-knowledge-check
title: Knowledge check
metadata:
  title: Knowledge check
  description: "Knowledge check"
  ms.date: 04/08/2024
  author: wwlpublish
  ms.author: jamesh
  ms.topic: unit
azureSandbox: false
labModal: false
durationInMinutes: 5
quiz:
  questions:
  - content: "Which user requirements are best suited for using HDInsight Interactive Query?"
    choices:
    - content: "When you want to use MapReduce on unstructured data with role-based access controls."
      isCorrect: false
      explanation: "MapReduce is better suited for a Hadoop cluster than an Interactive Query cluster."
    - content: "When you want to use SQL-like queries on structured data with row and column level controls."
      isCorrect: true
      explanation: "Interactive Query offers SQL-like queries, on structured data, with row and column level controls."
    - content: "When you want to use SQL-like queries on high concurrency data for long running-computations."
      isCorrect: false
      explanation: "Interactive Query clusters aren't suitable for long-running computations."
  - content: "What file formats are supported with Interactive Query?"
    choices:
    - content: ".xml, .doc, .log"
      isCorrect: false
      explanation: ".xml, .doc, and .log files aren't supported by Interactive Query."
    - content: ".json, .csv, .txt"
      isCorrect: true
      explanation: ".json, .csv, and .txt files are supported by Interactive Query."
    - content: ".PDF, .DBK, .MD"
      isCorrect: false
      explanation: ".PDF, DBK, MD files aren't supported by Interactive Query."
  - content: "Which scenario is best for HDInsight Interactive Query?"
    choices:
    - content: "Batch processing"
      isCorrect: false
      explanation: "Batch processing involves reading data from one location, transforming it and writing it to another location. Interactive Query is best for querying data as is, without the need for major transforming it."
    - content: "Streaming data."
      isCorrect: false
      explanation: "Streaming data is a hot-path scenario, where data is constantly being updated. Interactive Query is best for a cold-path scenario."
    - content: "Ad hoc queries"
      isCorrect: true
      explanation: "Ad hoc query scenarios require quick responses to interactive user queries. A great scenario for Interactive Query."
  - content: "Why is the Hive Warehouse Connector needed?"
    choices:
    - content: "Hive and Spark are different cluster types."
      isCorrect: false
      explanation: "Hive isn't a cluster type, only Spark is a cluster type."
    - content: "Hive and Spark have two different metastores. They require a connector to bridge between the two."
      isCorrect: true
      explanation: "Hive and Spark do have different metastores, and they require a bridge to connect the two."
    - content: "Hive is for static data and Spark is for streaming data."
      isCorrect: false
      explanation: "Hive works on static data and Spark works with streaming data, but that isn't why the Hive Warehouse Connector is necessary."
  - content: "Why is using the Hive Warehouse Connector more efficient and scalable than using a standard JDBC connection from Spark to Hive?"
    choices:
    - content: "Because the library loads data from the HiveServer into the spark driver in parallel"
      isCorrect: false
      explanation: "The library doesn't load data from the HiveServer into the Spark driver."
    - content: "Because the Hive Warehouse Connector is optimized for streaming data."
      isCorrect: false
      explanation: "The Hive Warehouse Connector can be used for streaming data, but that isn't why it's more efficient and scalable."
    - content: "Because the library loads data from LLAP daemons into Spark executors in parallel"
      isCorrect: true
      explanation: "The library loads data from LLAP daemons into Spark executors in parallel, which makes the Hive Warehouse Connector efficient and scalable."