Another foundational accessibility concept is related to the portrayal of important information from the game. Essential information from a game or platform should be presented to the player through multiple sensory channels, including vision, audio, and haptic or touch.

In this unit, you're introduced to the principle of multiple sensory channels as it applies to:

- Text-based information.
- Visual and audio cues.
- Notifications and status indicators.
- Directional cues.

## What are multiple sensory channels?

When gaming experiences provide important information to players, this information should be represented through multiple sensory channels. For example, an audio or haptic representation of information should accompany anything presented to the players visually. Similarly, visual or haptic indicators should accompany information portrayed through audio.

The use of multiple sensory channels can help ensure that players who can't perceive information presented visually are still aware of this information by consuming it through nonvisual channels.

## When should multiple sensory channels be used?

In general, multiple sensory channels should be used to represent information critical to successful interactions. Specific examples of these scenarios include the following areas.

### Text-based information

Games and platforms should provide players with an option to enable screen audio narration for all text-based elements within the UI. This narration includes menu, chat, notification, in-game tutorial, and objective log text. This narration provides players with visual disabilities access to important information represented through text.

### Visual and audio cues

Cues that are represented visually, like incoming enemy fire, the presence of nearby interactable objects, or nearby enemies, should also be represented through corresponding audio cues that have their own distinct sound. Similarly, cues that are conveyed through audio channels alone should have corresponding visual cues.

The following video capture from the game Grounded contains both visual and audio cues that inform the player that they are under attack. Corresponding audio cues like the player grunting when hit and the low-health beep pattern should accompany visual cues like the red attack halos and health meter actively depleting to convey the same information through two different sensory channels.

> [!VIDEO https://learn-video.azurefd.net/vod/player?id=a0c63709-b47a-4766-b59d-88a2e4f537e9]

### Directional cues

Navigating through a game is often a highly visual experience. It's important to represent visual information like the spatial location of an exit door, interactable object, or nearby enemy through audio channels. The representation of directional cues like waypoint markers and map locations are also a common source of accessibility barriers.

Consider representing this visual information through other audio cues like spatial audio pings or narrated directional cues. In the following video capture from the game Sea of Thieves, a player has the nautical narration setting enabled. As the player's character turns in space, moving the compass's direction, the current direction is narrated aloud through the audio channel.

> [!VIDEO https://learn-video.azurefd.net/vod/player?id=e1521cea-152d-4878-9509-97275b0a0003]
