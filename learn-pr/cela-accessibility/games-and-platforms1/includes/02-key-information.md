Another foundational accessibility concept is the presentation of important game information. Essential information from a game or platform should be presented to the player via multiple sensory channels, including vision, audio, and haptic (touch).

In this unit, you're introduced to the principle of multiple sensory channels as it applies to:

- Text-based information.
- Visual and audio cues.
- Directional cues.

## What are multiple sensory channels?

When gaming experiences provide important information to players, that information should be represented through multiple sensory channels. For example, an audio or haptic representation of information should accompany anything presented to the players visually. Similarly, visual or haptic indicators should accompany information portrayed through audio.

The use of multiple sensory channels can help ensure that players who can't perceive information presented visually are still aware of that information.

## When should multiple sensory channels be used?

In general, multiple sensory channels should be used to represent information that's critical to successful interactions. The following sections provide specific examples of these scenarios.

### Text-based information

Games and platforms should provide an option to enable screen audio narration for all text-based elements in the UI. These elements include menu, chat, notification, in-game tutorial, and objective log text. This narration enables players with visual disabilities to access important information in a way that doesn't require text.

### Visual and audio cues

Cues that are represented visually, like incoming enemy fire, the presence of nearby interactable objects, or nearby enemies, should also be represented via corresponding audio cues that have their own distinct sound. Similarly, cues that are conveyed through audio channels alone should have corresponding visual cues.

The following video capture from the game Grounded contains both visual and audio cues that inform players that they're under attack. Corresponding audio cues, like the player grunting when hit and the low-health beep pattern, accompany visual cues, like the red attack halos and health meter actively depleting, to convey the same information through two different sensory channels.

> [!VIDEO https://learn-video.azurefd.net/vod/player?id=a0c63709-b47a-4766-b59d-88a2e4f537e9]

### Directional cues

Navigating through a game is often a highly visual experience. It's important to represent visual information, like the spatial location of an exit door, interactable object, or nearby enemy, through audio channels. The representation of directional cues like waypoint markers and map locations are also a common source of accessibility barriers.

Consider representing this visual information via audio cues, like spatial audio pings or narrated directional cues. In the following video capture from the game Sea of Thieves, a player has the nautical narration setting enabled. As the player's character turns in space, moving the compass's direction, the current direction is narrated on the audio channel.

> [!VIDEO https://learn-video.azurefd.net/vod/player?id=e1521cea-152d-4878-9509-97275b0a0003]
