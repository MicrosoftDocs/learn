While AI offers significant benefits, its responsible use is essential to protect students and maintain trust with families and the community. Teachers must always maintain oversight to monitor AI use and outputs for fairness, privacy, and security. Microsoft's Responsible AI Principles (fairness, reliability and safety, privacy and security, inclusiveness, transparency, and accountability) provide a strong foundation for ethical classroom practice.

Responsible use means staying in control of the task, keeping student privacy at the center, and making your process transparent to students and families. The following workflow demonstrates how that looks in a Microsoft 365 classroom:

1. **Plan:** Choose tasks like creating accessible reading passages or multilingual family updates. Work inside your organization's Microsoft 365 tenant so prompts and outputs are protected by your district's policies. Use general descriptors (e.g., "a fifth-grade student who uses text to speech") rather than personally identifiable information unless your district has approved a tool for PII.

   > [!TIP]
   > Only use AI tools that have been approved by your district.

2. **Prompt:** Be specific and privacy-preserving. In **Copilot in Word**, you might ask: _"Draft three strengths-based reading goals for a fifth-grade student who benefits from text to speech and decodable texts. Use measurable language and include one example progress measure."_ In **Copilot in Outlook**, try: _"Draft a plain-language email to parents summarizing this week's reading activities (e.g., practicing decodable texts and using text-to-speech tools. Keep to 150 words. Offer translation availability."_ Both prompts give enough context to be useful, without disclosing PII.
3. **Review:** Keep a human in the loop for all your AI interactions. AI outputs are starting points. Check content for accuracy, bias, and fit. Verify facts, grade-level appropriateness, and alignment with your school's curriculum. Revise and ensure recommendations match your school's policies and intent. For example, a special educator using **Copilot in Word** to draft goal language might notice that the draft overgeneralizes. They refine it to reflect the student's current performance data and accommodations, then add Immersive Reader screenshots to model accessible reading strategies for families.
4. **Record:** Document prompts used and how you edited them. Add a one-line note in **Pages**: _"Used Copilot in Word to draft goal language; edited for accuracy, individualized strengths, and accessibility examples; no student PII entered in prompts."_ This satisfies accountability and helps you or an administrator retrace decisions later.
5. **Communicate:** Be transparent with families and colleagues. When you share a caregiver update drafted with **Microsoft 365** **Copilot**, include a simple sentence such as: _"This message was drafted with the help of Microsoft 365 Copilot and reviewed by me."_ If a caregiver requests an alternate language, use Microsoft Translator to provide a translated version, then reread it for tone and clarity. Transparency builds trust and reflects Microsoft's transparency principle.
6. **Evaluate:** Check impact and adjust. Use a quick before/after check each week: How many minutes did AI drafting save you? Did the final materials improve clarity or accessibility? Did the strategy support the student's targeted skill? Refine prompts based on what you learn.