Now we'll consider whether Azure Data Lake Storage is the correct choice for your organization's big data requirements. Your organization wants to control the costs of big data storage, especially the hardware and software expenditures associated with huge data volumes. Management wants to store every data type generated by your organization and is especially keen on removing all data silos that keep data sources separated. Your organization wants to make it easier to generate business insights from any data. And, finally, your organization wants to run analytics workloads on real-time data streams.

We'll list some criteria that indicate whether Azure Data Lake Storage will meet your performance and functional goals.

- Data size
- Data diversity
- Data completeness
- Data velocity

## Decision criteria

If your organization stores big data, it most likely uses a *data warehouse*. Administrators and data engineers know that traditional data warehouses:

- Have limits on how much data they can store.
- Aren't designed to store every type of data.
- Aren't designed to store all available data.
- Don't work well with high-velocity data.

These issues are irrelevant if your organization deals with relatively small datasets, a single type of data, subsets of your total data, or with data that comes in relatively slowly. To help you decide if Azure Data Lake Storage is a good fit for your organization, let's review the decision criteria in more detail.

### Data size

When deciding whether to move to a data lake from a traditional, on-premises data warehouse, one of the biggest factors is data size. Here, data size refers to both the overall amount of stored data and the size of individual files.

Data warehouses are purpose-built for dealing with large volumes of data, but there are hard limits on the total amount of data they can deal with:

- They use costly, high-end hardware for reliability and performance.
- Expansion is limited to the physical footprint of the data center.
- Their overall costs grow with data volume.
- They have ongoing costs for data center expenses such as cooling and security.

In comparison, Azure Data Lake Storage:

- Runs on virtual hardware on the Azure platform, so storage is scalable, fast, and reliable without incurring massive charges.
- Separates storage costs from compute costs. As your data volume grows, only your storage requirements change.
- Takes care of all costs associated with the data center.

### Data diversity

Is Azure Data Lake Storage a better choice when dealing with a diverse collection of data types?

First, let's review some of the reasons a traditional data warehouse might not be the best choice for diverse data. Data warehouses:

- Often have expensive and complicated configurations that only support certain data types.
- Rarely store raw data.
- Exclude data that's incompatible with the warehouse configuration.
- Often aren't configured for real-time data that comes in multiple formats; for example, JSON files, log files, and CSV files.
- Tend to store only those data types that are required by business analysts.

Azure Data Lake Storage overcomes these data access barriers, i.e. it enables so-called *data democratization*. It does this by enabling your organization to store all your data formats, including raw data, in a single location. The elimination of data silos enables users to open a tool such as Azure Data Explorer and use it to access and work with every data item in their storage account.

### Data completeness

Does Azure Data Lake Storage facilitate the storage of complete datasets?

Data warehouses aren't designed to store every piece of data generated by the organization:

- The incoming data is highly processed and much data generated by the organization is either incompatible with this processing or gets lost.
- To control costs, the stored data is almost always a subset of the total data.
- Data warehouses have policies that delete or archive old data, making it difficult to access.

Let's review how Azure Data Lake Storage compares to data warehouses. Azure Data Lake Storage:

- Doesn't process data in any way during ingestion, so all data is compatible and none gets lost.
- Stores all the available data, whether it's raw, semi-structured, or structured.
- Does not require the deletion or archiving of old data.

### Data velocity

Is Azure Data Lake Storage a suitable choice for the ingestion and storage of real-time data? Data warehouses are usually not ideal for handling high-speed streaming data because:

- Most data warehouses are configured for *batch input*, where the data is ingested in discrete transactions rather than in real time.
- The schema-on-read approach used by data warehouses is expensive and slow when applied to the high velocity of incoming streaming data.
- Data warehouses work best with structured data, but streaming data is often in a semi-structured format such as JSON.
- Data warehouses filter incoming data, but the analytics workloads for streaming data require access to the complete dataset.

By contrast, Azure Data Lake Storage was built with real-time data in mind. Azure Data Lake Storage:

- Can ingest real-time data directly from an instance of HDInsight Storm, Azure IoT Hub, Azure Event Hubs, or Azure Stream Analytics.
- Doesn't apply a schema during ingestion, so there's no incoming bottleneck for real-time data.
- Works with semi-structured data.
- Lets you ingest all your real-time data into your storage account.

Azure Data Lake Storage also enables you to output the ingested streaming data to various Azure services, such as Azure Machine Learning and Azure Stream Analytics.

## Apply the criteria

To decide whether Azure Data Lake Storage is a suitable solution for your organization, review the following use cases and recommendations.

### Should you use Azure Data Lake Storage to lower costs?

Organizations might not save much money by moving from a data warehouse to a data lake if they deal with:

- Relatively small amounts of data.
- Data that is generated or modified relatively slowly.

However, you should consider using Azure Data Lake Storage to reduce TCO if your organization:

- Generates massive amounts of data.
- Generates new data quickly.
- Makes frequent changes to the data configuration.
- Incurs costs for hardware, software, and maintenance that take up a significant and increasing portion of your IT budget.

For example, a national package delivery business generates huge amounts of structured and real-time data, so data costs are a major concern. Azure Data Lake Storage would be a good fit to achieve the organization's goal of controlling data costs.

### Should you use Azure Data Lake Storage to improve data access?

Organizations might not require the improved data access that comes from moving to Azure Data Lake Storage if they:

- Want to tightly control how users access data.
- Don't need to store raw and semi-structured data.

However, you should consider using Azure Data Lake Storage to enhance data democratization if your organization:

- Wants to prevent the data silos that occur when separate datasets can't be queried or integrated.
- Wants to give users access to all of your organization's data.
- Wants to give users more flexibility in the tools they use to access the data.

Our package delivery business is likely riddled with data silos because it has many different departments that generate their own large datasets. Azure Data Lake Storage would eliminate those data silos and increase access to all the organization's data.

### Should you use Azure Data Lake Storage for data insights?

Using Azure Data Lake Storage for data insights might not be suitable for organizations that:

- Have a narrow scope of what they want to study when analyzing data.
- Employ business professionals to analyze most of the data.

However, you should consider using Azure Data Lake Storage for data insights if any of the following conditions if your organization:

- Wants to offer users a more flexible approach to exploring the data.
- Wants to give analysts access to raw and semi-structured data.
- Wants users to be able to build models and sandboxes that use any or even all of the available data.

The package delivery business is a competitive industry that requires innovation and speed, which requires business insight. Azure Data Lake Storage would be a good fit for generating those insights by giving analysts access to all the company's data.

### Should you use Azure Data Lake Storage for real-time analysis?

You don't need Azure Data Lake Storage to handle real-time data if:

- Your organization's streaming data has a relatively slow velocity and comes in a single data format (such as JSON files)
- Your data warehouse is configured to handle that data format by applying any processing.

However, you should consider using Azure Data Lake Storage for real-time analytics if your organization:

- Ingests streaming data that comes in very fast.
- Ingests real-time data that arrives in multiple data formats.
- Wants to apply multiple types of analytics workloads to the data, such as machine learning, model prediction, and sentiment analysis.

The package delivery business generates real-time data courtesy of the delivery truck IoT sensors, the dash cam video feeds, and the web server logs. Azure Data Lake Storage is an ideal choice to run analytics workloads on real-time data streams.