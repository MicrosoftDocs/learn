Let's begin with a quick overview of Azure Data Lake Storage and its core features. This overview should help you decide whether Azure Data Lake Storage is worth considering as a solution for your company's big data storage requirements.

## What is a data lake?

A *data lake* is a centralized repository that you can use to store all your data—both structured and unstructured—in a single location. With a data lake, there's no need to conform your data to fit an existing structure. Instead, you can store your data in its raw or native format, usually as files or as binary large objects (blobs).

When evaluating whether a data lake is the correct solution for your company, there are several elements to consider, as described in the following table.

| **Element**        | **Description**  |
| --- | --- |
| **Data speed**      | A data lake must be able to ingest data at any speed: from the occasional file to large relational data imports to real-time data generated by web server logs or IoT devices. |
| **Data scalability** | A data lake might be required to store massive amounts of data that arrive in real time, so the storage must be highly scalable to keep up with the demand. |
| **Data availability** | After files, blobs, or relational data are stored in a data lake, they must be readily available through browsing, searching, and indexing of the data. |
| **Data security**      | Most data lakes store crucial data assets, including line-of-business data, company-developed apps, and productivity output. The data lake requires robust security to protect these assets.    |
| **Data analytics** | A data lake must store data in a way that enables business analysts, data scientists, and AI modelers to use their preferred tools to analyze the data in place to derive business intelligence, insights, trends, and forecasts. |
| | |

A data lake enables your organization to quickly and easily store, access, and analyze a wide variety of data in a single location.

## Azure Data Lake Storage definition

Azure Data Lake Storage is a cloud-based, enterprise data lake solution engineered to store massive amounts of data in any format and to facilitate big data analytical workloads. You can use Azure Data Lake Storage to capture data of any type and ingestion speed in a single location for easy access and analysis using a variety of frameworks.

> [!NOTE]
> The current implementation of Azure's data lake storage service is Azure Data Lake Storage Gen2. You might notice references to the previous implementation, Azure Data Lake Storage Gen1, which is scheduled to be retired on February 29, 2024.

To better understand Azure Data Lake Storage, you can examine its following characteristics:

- Data storage
- Data access
- Data costs
- Data performance
- Data security
- Data redundancy
- Data scalability
- Data analysis

### Data storage

Azure Data Lake Storage can store any type of data by using the native format of that data. You don't need to define a schema or perform any type of transformation on the data before ingesting the data. Also, Azure Data Lake Storage doesn't perform any special handling of data based on the type of data it stores. With support for any data format and massive data sizes, Azure Data Lake Storage can work with structured, semi-structured, and unstructured data.

### Data access

Azure Data Lake Storage is primarily designed to work with Hadoop and all frameworks that use the Hadoop Distributed File System (HDFS) as their data access layer. Hadoop distributions include the Azure Blob File System (ABFS) driver, which enables many applications and frameworks to access Azure Blob Storage data directly.

A key feature that enables Azure Data Lake Storage to provide high-performance data access at object storage scale and prices is *hierarchical namespace*. You can use this feature to organize all the objects and files within your Azure Data Lake Storage account into a hierarchy of directories and nested subdirectories. In other words, your Azure Data Lake Storage data is organized in much the same way that files are organized on your computer.

> [!IMPORTANT]
> Hierarchical namespace is *not* enabled by default. When you create a storage account, you must select the **Enable Hierarchical Namespace** check box. Note, as well, that you can't enable this feature on existing storage accounts, only on new storage accounts.

### Data costs

Azure Data Lake Storage is priced at Azure Blob Storage levels. It builds on the powerful Azure Blob Storage capabilities such as Automated Lifecycle Policy Management and Object Level tiering to manage big data storage costs. By using a hierarchical namespace, an Azure Data Lake Storage account provides the scalability and cost-effectiveness of object storage.

### Data performance

The hierarchical namespace supported by Azure Data Lake Storage allows for efficient access and navigation. This architecture means that data processing requires fewer computational resources, which reduces both the speed and cost of accessing data.

Azure Data Lake Storage supports high throughput for input/output intensive analytics and data movement. To get the best performance from Azure Data Lake Storage, it's important to use all the available throughput, which is the amount of data that can be read or written per second. Azure Data Lake Storage achieves throughput maximization by performing as many reads and writes in parallel as possible.

### Data security

The Azure Data Lake Storage access control model supports both Azure role-based access control (Azure RBAC) and Portable Operating System Interface (POSIX) access control lists (ACLs). There are also a few extra security settings that are specific to Azure Data Lake Storage. You can set permissions either at the directory level or at the file level. All stored data is encrypted at rest by using either Microsoft-managed or customer-managed encryption keys.

You can configure security settings a number of ways, including the following app and frameworks:

- Azure Storage Explorer
- Azure command-line interface
- Java
- JavaScript (Node.js)
- .NET
- PowerShell
- Python
- REST API

### Data redundancy

Azure Data Lake Storage takes advantage of the Azure Blob replication models that provide data redundancy in a single datacenter with locally redundant storage (LRS), or to a secondary region by using the Geo-redundant storage (GRS) option. This feature helps ensure that your data is always available and protected if there is an outage.

### Data scalability

Azure Data Lake Storage offers massive storage and can accept a variety of data types for analytics. It doesn't impose any limits on account sizes, file sizes, or the amount of data that can be stored in the data lake. Individual blobs and files can have sizes that range from a few kilobytes to a few petabytes. All of this means that Azure Data Lake Storage can easily and quickly scale up to meet the most demanding workloads, then just as easily scale back down when demand drops.

### Data analysis

Data analysis frameworks that use HDFS as their data access layer can directly access Azure Data Lake Storage data through ABFS. The Apache Spark analytics engine and the Presto SQL query engine are examples of such frameworks.

In Azure, Data Lake Storage integrates with the following frameworks for analysis:

- Azure HDInsight
- Azure Machine Learning
- Azure Synapse Analytics
- Microsoft Power BI

> [!NOTE]
> Azure Data Lake Storage is also integrated into a massive and mature analytics ecosystem associated with Azure Blob Storage.

## How to prevent data silos

Data silos occur when different data sources are stored in separate locations, each of which can only be accessed by a specific application or framework. For example, a business analyst or data scientist who wants to analyze both sales data and web server logs must perform the following general steps:

1. Access one set of data.
1. Query the data.
1. Download the query results.
1. Repeat steps 1 through 3 for each set of data.
1. Process the downloaded data in a way that makes it possible to analyze the two datasets together.
1. Analyze the processed data.

That's a time-consuming, convoluted, and complex process. However, if all the required data is stored in Azure Data Lake Storage, the business analyst or data scientist can use their tool of choice—such as Power BI or Azure HDInsight—to work directly with all the data they need. Azure Data Lake Storage leaves it up to the individual analytic framework to interpret the data and define a schema at the time of the analysis.
