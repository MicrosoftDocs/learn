As Contoso adopts AI-powered services, new risks emerge around how sensitive information is used, generated, and exposed through AI interactions. Security teams need to ensure that AI tools process data securely, apply protections consistently, and prevent sensitive content from being misused.

## Risks introduced by AI services

AI tools increase efficiency but also create new exposure risks:

- Sensitive information might appear in AI-generated responses.
- Prompts submitted to AI models might include sensitive or confidential data.
- AI-generated content might be shared, stored, or used without proper controls.

Security policies must address how AI services handle both input and output data to prevent unintended disclosure.

## Microsoft Purview protections for AI interactions

Microsoft Purview includes protection controls that extend to AI services:

- **Data loss prevention (DLP) for AI services**: DLP policies can evaluate prompts and responses submitted to supported AI services, applying protections to prevent sensitive information exposure.
- **Sensitivity labels and encryption**: AI-generated content stored in Microsoft 365 services can inherit sensitivity labels and apply encryption, ensuring data remains protected even after it's processed.
- **Insider risk management**: Policies can monitor risky activity that involves AI services, such as submitting confidential data into public or unmanaged AI tools.

By extending these protections to AI interactions, Contoso ensures that sensitive information remains protected even as AI tools become part of everyday workflows.
