AI tools introduce risks that traditional data protection strategies might not cover. These include the inclusion of sensitive data in prompts or the use of broadly shared content in AI-generated responses. These tools can also surface content in ways that create compliance gaps if not handled carefully.

Microsoft Purview addresses these challenges by extending its existing protections to AI interactions. You learned how to use sensitivity labels and data loss prevention policies to apply consistent access and usage controls, and how Adaptive Protection responds to increased user risk by enforcing stricter policies. Tools like Insider Risk Management and Communication Compliance help detect AI-related actions that violate policy, while Compliance Manager tracks readiness against regulatory standards.

Data Security Posture Management (DSPM) for AI helps security teams assess where sensitive content might be exposed and guides configuration of relevant protections. Retention and eDiscovery tools ensure that AI prompts and responses can be preserved and retrieved during audits or investigations.

In this module you learned how to:

- Identify and assess AI-related risks to sensitive data
- Apply protections based on the type of AI tool in use
- Address risky AI interactions and respond to policy violations
- Retain and search AI interaction data for legal or compliance scenarios
- Evaluate control effectiveness using Compliance Manager
- Use DSPM for AI to guide protection strategies across Microsoft Purview

These capabilities help organizations apply consistent safeguards across AI interactions while maintaining compliance and reducing the risk of inappropriate data use.

## References

- [Microsoft Purview data security and compliance protections for generative AI apps](/purview/ai-microsoft-purview?azure-portal=true)
- [Learn about Data Security Posture Management (DSPM) for AI](/purview/dspm-for-ai?azure-portal=true)