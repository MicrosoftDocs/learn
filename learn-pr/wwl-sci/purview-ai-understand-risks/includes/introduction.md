AI tools like Microsoft Copilot and ChatGPT are changing how users access and interact with data. These tools can summarize, generate, and analyze content quickly, but that speed also increases the risk of exposing sensitive or regulated information. Most traditional data security controls werenâ€™t designed to address how AI tools handle data, especially in enterprise environments.

Microsoft Purview helps reduce these risks by applying consistent protections across AI interactions. Organizations can assess how AI tools use sensitive data, apply access and usage controls, and retain content when needed for investigations or compliance reviews. These capabilities work across Copilot, enterprise AI apps, and browser-based tools.

## Learning objectives

By the end of this module, you'll understand how to:

- Identify security, compliance, and data exposure risks introduced by AI tools
- Use Microsoft Purview protections such as sensitivity labels, DLP policies, and Adaptive Protection to reduce AI-related risk
- Detect and address risky AI activity using Insider Risk Management and Communication Compliance
- Retain, search, and export AI prompts and responses for legal or compliance needs
- Evaluate organizational readiness using Compliance Manager assessments
- Use DSPM for AI to assess how sensitive data is accessed or referenced in AI scenarios
