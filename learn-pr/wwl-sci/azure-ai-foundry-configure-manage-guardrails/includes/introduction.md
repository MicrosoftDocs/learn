As organizations scale their use of generative AI, managing safety across different workloads becomes increasingly complex. Models need to protect sensitive data, respond appropriately to user input, and stay aligned with organizational policies, all without slowing innovation.

**Azure AI Foundry guardrails** help teams design and enforce these protections through configurable controls that evaluate both prompts and responses. Guardrails such as content filters, blocklists, and Prompt Shields create consistent boundaries that keep AI workloads secure, compliant, and productive.

## Learning objectives

In this module, you learn to:

- Explain how guardrails secure model interactions in Azure AI Foundry
- Describe safety controls such as content filters, blocklists, and Prompt Shields
- Configure and validate custom guardrails for different workload types
- Evaluate guardrail effectiveness and refine configurations for continuous assurance

## Prerequisites

Before starting, you should have:

- Experience managing Azure AI or cloud-based workloads
- Familiarity with AI model deployment and data security concepts
- Awareness of organizational policy or compliance requirements related to AI use
