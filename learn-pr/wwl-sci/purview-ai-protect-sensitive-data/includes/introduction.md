AI tools like Microsoft 365 Copilot, ChatGPT, and Copilot for Bing are changing how users create, access, and share information. These tools can summarize, generate, and analyze content at scale, helping people work more efficiently. At the same time, they introduce new risks. Sensitive data can be accessed, misclassified, or shared in ways that traditional security controls werenâ€™t designed to prevent.

Organizations need tools that account for how AI interacts with sensitive content and that can apply consistent protections across common AI tools.

This module explains how Microsoft Purview helps protect sensitive data in AI interactions. You'll learn how sensitivity labels are used in Microsoft 365 Copilot, how endpoint data loss prevention (DLP) can restrict actions like pasting and uploading into AI sites, and how data assessments help detect oversharing risks. These tools support secure and responsible AI use across the organization.

## Learning objectives

By the end of this module, you'll understand how to:

- Use sensitivity labels to control how AI tools access and handle content
- Configure Endpoint DLP to restrict risky actions in browsers
- Run data assessments to detect oversharing risks in SharePoint
