Generative AI can increase the risk of exposing sensitive data by surfacing misclassified, over-permissioned, or outdated content. Traditional protection methods often don't account for how these tools access and process information.

Microsoft Purview provides protections that help address these risks. You learned how sensitivity labels help control access to content and how endpoint data loss prevention (DLP) can block risky actions in browsers. You also learned how data assessments detect and help you respond to oversharing risks in SharePoint.

In this module you learned how to:

- Use sensitivity labels to control how AI tools access and handle content
- Configure endpoint DLP to restrict risky actions in browsers
- Run data assessments to detect oversharing risks in SharePoint

These capabilities support responsible AI use by helping organizations apply consistent protections across AI interactions.

## Resources

- [Data, Privacy, and Security for Microsoft 365 Copilot](/copilot/microsoft-365/microsoft-365-copilot-privacy?azure-portal=true)
- [Microsoft Purview data security and compliance protections for generative AI apps](/purview/ai-microsoft-purview?azure-portal=true)
- [Learn about sensitivity labels](/purview/sensitivity-labels?azure-portal=true)
- [Get started with Microsoft 365 Copilot - admin guide](/copilot/microsoft-365/microsoft-365-copilot-setup?azure-portal=true)
- [Get started with endpoint data loss prevention](/purview/endpoint-dlp-getting-started?azure-portal=true)
