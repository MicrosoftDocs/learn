AI agents and copilots can generate, access, and return sensitive or regulated information. They might summarize SharePoint files, analyze Power BI datasets, or respond to questions in Microsoft Teams. Because these interactions involve sensitive data, they require consistent protection and governance.

Microsoft Purview provides safeguards for developer AI apps by classifying, restricting, retaining, and investigating prompt data. Using tools such as sensitivity labels, DLP policies, retention, audit, and eDiscovery, organizations can apply the same governance standards to AI interactions that already protect files, emails, and other content.

## Use sensitivity labels to control access and classification

Sensitivity labels apply classification and protection to files, emails, and other Microsoft 365 content. In AI scenarios, sensitivity labels can influence:

- Whether content is included in agent responses (for SharePoint and Copilot Studio scenarios)
- How content is processed by copilots in Microsoft 365
- What data is visible to copilots based on label scope and encryption settings

For example, in **Copilot Studio**, SharePoint files labeled **Highly Confidential** can be excluded from summarization based on your policy settings. In **Microsoft 365 Copilot**, data loss prevention (DLP) policies can reference sensitivity labels to block specific content from being included in responses.

## Understand label inheritance in AI interactions

When AI agents use Microsoft 365 data sources, label inheritance can affect how prompts and responses are treated. Content retrieved by copilots or agents might retain the sensitivity label of the source document, influencing both how the data is used and how it's logged or retained.

For example:

- In **Copilot in Fabric**, labels applied to Power BI datasets might influence what data Copilot can summarize.
- In **Copilot Studio**, prompts and responses might inherit classification based on accessed documents or files.

This behavior supports consistent labeling across generated or referenced content, helping enforce your classification policies even in conversational or generative use cases.

## Apply DLP policies to restrict sensitive responses

Microsoft Purview DLP policies allow you to block or restrict AI-generated responses that include sensitive content. You can scope DLP rules to the **Microsoft 365 Copilot** location and configure conditions such as:

- Block summarization of content labeled **Confidential** or higher
- Allow referencing file names only for files with sensitive info types
- Require user justification before content is returned

DLP policies apply to copilots embedded in Microsoft 365 apps and to custom copilots built in Copilot Studio that use supported Microsoft 365 data sources.

## Retain AI interactions using retention policies and labels

Prompts and responses from copilots and AI agents can be stored in Exchange Online when logging is enabled. Once stored, retention labels and policies can help manage the lifecycle of this data.

- **Retention labels** let you classify and apply granular retention rules to content, such as specific AI interactions. Labels are published through **retention label policies**, which by default can target standard locations like Exchange mailboxes, SharePoint sites, OneDrive accounts, and Microsoft 365 Groups.
- **Retention policies** provide broader coverage, allowing you to preserve or delete all Copilot interactions in a location for a defined period. Labels provide more precise control, while policies apply broadly across interaction data.

> [!NOTE]
> To include AI-specific locations like **Microsoft Copilot Experiences**, **Enterprise AI apps**, or **Other AI apps**, your tenant must have pay-as-you-go billing enabled.

## Log and investigate AI activities with audit

Microsoft Purview Audit captures events when copilots and agents are used across supported services. For developer AI apps, these logs provide the activity-level detail needed to investigate how copilots and agents are being used.

Audit logs can show:

- Which user interacted with a custom copilot or agent
- When the interaction occurred
- Which app, service, or Microsoft Entra-registered application was involved

By reviewing Audit logs for AI interactions, you can identify unusual patterns of activity and determine whether further safeguards are required.

## Investigate AI content with eDiscovery

Microsoft Purview eDiscovery makes it possible to search, review, and export AI prompts and responses that are in Exchange Online when logging is enabled. This allows legal, compliance, or security teams to investigate content generated by developer AI apps in the same way they would email or documents.

In eDiscovery, you can:

- Search prompts and responses by keyword, label, user, or time range
- Review AI interaction content alongside other Microsoft 365 data
- Export results for legal review or incident investigations

By making developer AI prompts and responses discoverable, eDiscovery supports compliance obligations and ensures investigations are comprehensive.
