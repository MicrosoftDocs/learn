Apps built with Azure AI services or Azure AI Foundry often connect to sensitive data sources. Without governance, they can generate or share regulated information outside approved boundaries. Microsoft Purview lets you onboard these apps so protections such as data loss prevention (DLP), retention, and eDiscovery apply consistently, even when the app is hosted outside Microsoft 365.

## Onboard Azure AI apps to Microsoft Purview

Unonboarded Azure AI apps fall outside Microsoft Purview, leaving protections like DLP and retention unenforced. Before you can apply protections, apps built with Azure AI must be onboarded into Microsoft Purview.

If the app is registered in Microsoft Entra ID, onboarding typically involves:

- Authorizing access to Microsoft 365 data
- Assigning the appropriate Microsoft Graph API permissions, such as `Mail.Read` or `Sites.Read.All`, depending on which data the app needs to access
- Making sure Purview-supported signals are enabled for the app

For apps that use data sources outside Microsoft 365, such as files stored in Azure or on external services, you might need to configure Data Security Posture Management (DSPM) for AI collection policies. These policies allow you to capture prompt activity and file access from Azure-hosted apps so they can appear in Microsoft Purview.

Once onboarded, apps become visible in DSPM for AI reports and can be included in policy scopes for DLP and other Microsoft Purview tools.

> [!NOTE]
> To view or manage onboarding in DSPM for AI, users need the correct Microsoft Purview or Microsoft Entra permissions. For details, see [Permissions for Data Security Posture Management for AI](/purview/dspm-ai-permissions?azure-portal=true).

## Apply DLP policies to Azure AI apps

Even after onboarding, apps might still return or share sensitive content unless DLP policies restrict them. DLP policies help you detect and restrict how Azure AI apps interact with sensitive content. If an app accesses Microsoft 365 data, you can apply policies that trigger when:

- Files with sensitivity labels are accessed
- Confidential content is used in a generated response
- Protected data is sent or shared by the app

You can scope DLP policies to apply to Microsoft Entra-registered apps, including those built with Azure AI services. These policies can audit or block actions such as copying, summarizing, or storing protected content.

If you use DSPM for AI collection policies to capture prompts and responses, you can create DLP rules that inspect the text generated by the app. For example, you could create a policy that detects when a response includes personal identifiers or financial information pulled from a protected SharePoint site.

## Retain and investigate AI content with Microsoft Purview

Prompts and responses from Azure AI apps can contain sensitive business data. Without retention, they might be lost before compliance reviews or investigations.

Retention policies allow you to preserve this content for a defined period based on your organization's compliance or business requirements. You can apply retention across all collected AI interactions or scope it to specific users, apps, or data types.

Captured content is also available in **eDiscovery**. You can use it to:

- Search for prompts or responses based on keywords, users, or time ranges
- Review AI interactions alongside other content like email or documents
- Export results for legal or compliance investigations

Bringing Azure AI apps into Microsoft Purview ensures sensitive data is retained, reviewable, and subject to the same compliance standards as other workloads.
