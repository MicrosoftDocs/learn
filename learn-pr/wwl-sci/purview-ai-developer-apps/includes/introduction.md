Custom AI apps offer flexibility to developers, but they also introduce new data security and compliance challenges. These apps often access sensitive information and generate responses that could result in unintended data exposure if not properly governed.

In this module, you take on the role of a security or compliance administrator responsible for securing AI environments built with Azure AI, Microsoft Entra, Copilot Studio, and Microsoft Fabric. You'll use Microsoft Purview to discover these apps, assess their risks, and apply the right protections based on data sensitivity, usage patterns, and regulatory requirements.

In this module, you:

- Understand the security and compliance risks associated with developer AI environments
- Discover and assess AI apps using Data Security Posture Management (DSPM) for AI
- Enforce protections for Azure AI services and Entra-registered apps
- Govern custom agents created in Copilot Studio
- Classify and retain prompt and response content
- Investigate risky AI activity using tools like Insider Risk Management, Communication Compliance, and Audit

By the end of this module, you'll know how to apply Microsoft Purview tools to secure AI usage in developer-driven environments and maintain consistent protections across AI platforms.
