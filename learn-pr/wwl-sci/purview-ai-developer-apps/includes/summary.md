AI applications built by developers can unlock powerful new capabilities, but they also bring new risks that must be addressed with the right policies and tools. In this module, you acted as a security or compliance administrator focused on securing custom AI environments built on Azure AI, Microsoft Entra, Copilot Studio, and Microsoft Fabric.

You learned how to:

- Use DSPM for AI to discover apps, assess risks, and guide protection decisions
- Apply sensitivity labels, data loss prevention, and retention to AI-generated content and data sources
- Capture and retain AI prompt data for compliance and investigation
- Review activity using Microsoft Purview tools like Audit and eDiscovery
- Detect risky or inappropriate usage with Insider Risk Management and Communication Compliance

Without these protections, AI apps can operate with limited visibility and inconsistent data handling. With Microsoft Purview, you created a foundation for securing developer AI environments while supporting innovation and compliance at scale.

## Resources

- [Use Microsoft Purview to manage data security & compliance for Microsoft Copilot Studio](/purview/ai-copilot-studio?azure-portal=true)
- [Use Microsoft Purview to manage data security & compliance for Entra-registered AI apps](/purview/ai-entra-registered?azure-portal=true)
- [Use Microsoft Purview to manage data security & compliance for Azure AI services](/purview/ai-azure-services?azure-portal=true)
- [Secure and Compliant AI App Development & Deployment in Azure AI Foundry with Microsoft Purview](/purview/developer/secure-ai-with-purview?azure-portal=true)
- [Configure Microsoft Purview solutions in Data Security Posture Management (DSPM) for AI for Custom AI Applications](/purview/developer/configurepurview?azure-portal=true)
