AI applications built by developers can unlock powerful new capabilities, but they also bring new risks that must be addressed with the right policies and tools. In this module, you acted as a security or compliance administrator focused on securing custom AI environments built on Azure AI, Microsoft Entra, Copilot Studio, and Microsoft Fabric.

You learned how to:

- Use DSPM for AI to discover apps, assess risks, and guide protection decisions
- Apply sensitivity labels, DLP, and retention to AI-generated content and data sources
- Capture and retain AI prompt data for compliance and investigation
- Review activity using Microsoft Purview tools like Audit and eDiscovery
- Detect risky or inappropriate usage with Insider Risk Management and Communication Compliance

Without these protections, AI apps can operate with limited visibility and inconsistent data handling. With Microsoft Purview, you created a foundation for securing developer AI environments while supporting innovation and compliance at scale.
