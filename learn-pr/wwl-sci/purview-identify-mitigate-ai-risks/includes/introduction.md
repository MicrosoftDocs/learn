AI tools like Microsoft 365 Copilot are changing how organizations work with data, but they also introduce new security and compliance risks. Traditional security controls weren't designed to track AI interactions or protect sensitive data in AI-generated content. Without a way to monitor AI activity and enforce security policies, organizations risk data exposure, compliance violations, and security gaps.

**Microsoft Purview Data Security Posture Management (DSPM) for AI** helps security teams manage these risks by providing insights into AI activity, security policies to protect sensitive data, and compliance controls to enforce governance. With DSPM for AI, organizations can track AI usage, assess security risks, and apply protections to prevent unauthorized data exposure.

## Scenario

Your organization has started using Microsoft 365 Copilot to improve productivity. Security teams don't have a clear way to track how it's used or what data it accesses. Without visibility, they can't tell if AI-generated content includes sensitive information or if users are sharing regulated data with external AI tools.

To solve this, your team needs to use DSPM for AI to monitor AI interactions, detect potential security risks, and apply policies that protect sensitive information.

## Learning objectives

By the end of this module, you'll be able to:

- Identify security risks in AI interactions
- Monitor AI usage and enforce security policies
- Protect sensitive data in AI-generated content
- Run data assessments to detect oversharing risks
- Use reports to track AI activity and strengthen compliance
