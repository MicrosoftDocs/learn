Enterprise and public AI tools like ChatGPT Enterprise, Claude, and Perplexity are being used across industries, but many operate outside traditional IT governance. Without the right visibility and controls, these tools can expose sensitive data, create compliance gaps, or allow risky behavior to go unnoticed.

In this module, you're responsible for identifying, assessing, and securing interactions with both enterprise-approved and unmanaged AI applications. Using Microsoft Purview, you discover how users interact with these tools, apply data protections, and retain AI-generated content to meet your organization's compliance needs.

You'll learn how to:

- Understand which AI tools pose the highest data exposure risks
- Discover and assess AI usage with Data Security Posture Management (DSPM) for AI and Compliance Manager
- Detect policy violations in AI prompts and responses with Communication Compliance
- Analyze user behavior and assign risk levels using Insider Risk Management
- Apply risk-based data loss prevention policies through Adaptive Protection
- Retain AI interaction content using Microsoft Purview retention policies

By the end of this module, you'll understand how to use Microsoft Purview to manage data risks and compliance requirements across both managed and unmanaged AI environments.
