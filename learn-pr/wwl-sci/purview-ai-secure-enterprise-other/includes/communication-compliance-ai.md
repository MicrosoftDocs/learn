Communication Compliance helps your organization detect risky, inappropriate, or noncompliant content in AI prompts and responses, even when users interact with non-Microsoft or browser-based tools. By analyzing content submitted to or generated by generative AI applications, Communication Compliance identifies potential violations of your organization's policies and flags them for review.

This capability is available for Microsoft 365 Copilot and also applies to other AI interaction locations, including:

- **Enterprise AI apps**: Tools formally approved or provisioned by your organization, often registered through Microsoft Entra ID or connected using Microsoft Purview Data Map.
- **Other AI apps**: Public browser-based tools such as Gemini, Claude, or Perplexity that operate outside of identity or policy frameworks.

Communication Compliance lets you surface issues such as inappropriate use of sensitive data, sharing of confidential content, or unethical interactions. It does this without blocking access or disrupting productivity.

## Create a Communication Compliance policy for AI apps

To analyze interactions with enterprise and non-Microsoft AI tools:

1. In the Microsoft Purview portal, go to **Solutions** > **Communication Compliance**.

1. Select **Policies**, then choose **Create policy**.

1. Select a policy template that matches your scenario, or choose to create a custom policy.

1. On the **Name and describe your policy** page, enter a name and optional description.

1. On the **Choose users and reviewers** page, select the users and groups in scope, exclude any users if needed, and assign reviewers.

1. On the **Choose locations to detect communications** page, select one or more generative AI locations:

   - **Microsoft Copilot experiences**
   - **Enterprise AI apps**
   - **Other AI apps**

      :::image type="content" source="../media/communication-compliance-ai-locations.png" alt-text="Screenshot showing selected communication detection locations, including Exchange, Teams, Viva Engage, and generative AI options like Copilot and other AI apps." lightbox="../media/communication-compliance-ai-locations.png":::

1. On the **Choose conditions and review percentage** page, adjust the **Review percentage** to control how often interactions are flagged. You can also add conditions such as:

   - Sensitive information types
   - Keyword dictionaries
   - Trainable classifiers
   - Content safety classifiers

1. Review your policy settings, then select **Create policy**.

> [!NOTE]
> Detection for enterprise and other AI apps requires enabling pay-as-you-go billing.

## Review policy matches and violations

AI policy matches appear in the **Pending** tab in Communication Compliance. Each match includes metadata such as:

- The AI tool used (Copilot, Connected AI app, or Cloud AI app)
- The sender (often Copilot or Connected AI app) and recipient (the end user)
- The matched text that triggered the policy
- An icon and subject tag identifying the interaction as AI-related

Prompts and responses are shown separately, helping reviewers pinpoint the exact interaction that matched the policy.

Reviewers can take standard actions including tagging, resolving, escalating, downloading, or exporting the item.

> [!TIP]
> DSPM for AI can recommend Communication Compliance policies when risks are detected in Microsoft 365 Copilot interactions. To monitor enterprise or browser-based AI apps, you'll need to create or customize a policy manually.

## Get insights from alerts and reports

Matches for enterprise and other AI tools behave like matches for email or Teams:

- You'll see them in the **Pending** tab, **Alerts**, and **Reports** dashboards.
- You can investigate, remediate, or export them just like other policy violations.
- Activity is included in audit logs for compliance and tracking.

Communication Compliance gives your organization visibility into how people use AI tools and helps you take action when interactions violate your policies. With the right conditions and review settings, you can analyze prompts and responses across enterprise and public AI apps while keeping access flexible for users.
