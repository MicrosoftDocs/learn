Securing AI interactions is essential as tools like Microsoft 365 Copilot become part of everyday work. In this module, you acted as a security or compliance administrator responsible for protecting data, enforcing responsible use, and maintaining regulatory compliance.

You learned how to:

- Control Copilot's access to sensitive content with sensitivity labels
- Prevent data exposure in Copilot interactions using data loss prevention policies
- Retain and audit Copilot prompts and responses with retention and audit
- Investigate Copilot activity using eDiscovery
- Detect risky or inappropriate Copilot usage with Communication Compliance
- Assess AI compliance using Compliance Manager

Without these tools, organizations risk inconsistent protection, limited visibility, and increased exposure. With Microsoft Purview, you applied targeted policies that help secure AI usage at scale while supporting productivity without compromising security or compliance.

## References

- [Learn about sensitivity labels](/purview/sensitivity-labels?azure-portal=true)
- [Learn about the Microsoft 365 Copilot policy location](/purview/dlp-microsoft365-copilot-location-learn-about?azure-portal=true)
- [Learn about retention for Copilot & AI apps](/purview/retention-policies-copilot?azure-portal=true)
- [Audit logs for Copilot and AI applications](/purview/audit-copilot?azure-portal=true)
- [Configure a Communication Compliance policy to detect for generative AI interactions](/purview/communication-compliance-copilot?azure-portal=true)
- [Search for and delete AI application data in eDiscovery](/purview/edisc-search-copilot-data?azure-portal=true)
