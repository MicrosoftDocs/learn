AI workloads are transforming how organizations build applications, but they also introduce new risks that traditional cloud security controls don't fully address. Models can be manipulated through crafted prompts, sensitive data can surface in outputs, and governance requirements now extend beyond infrastructure.

Securing AI workloads requires understanding how Azure services work together to manage risk. By combining posture management, model guardrails, data governance, and identity protection, organizations can maintain consistent security coverage across the AI lifecycle.

## Learning objectives

In this module, you learn to:

- Identify the layers that make up AI workloads in Azure
- Recognize security risks unique to AI, including prompt injection, data leakage, and model misuse
- Explain how Azure AI Foundry provides guardrails and observability for AI models
- Describe how Microsoft Defender for Cloud, Microsoft Purview, and Microsoft Entra ID support AI security and governance

## Prerequisites

Before starting, you should have:

- Experience managing Azure workloads and security controls
- Familiarity with concepts such as identity and access management, network isolation, and cloud security posture management (CSPM)
- Awareness of how traditional cloud security principles extend to AI workloads
