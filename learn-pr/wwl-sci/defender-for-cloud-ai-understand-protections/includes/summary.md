AI workloads add new dimensions to cloud security by introducing model behavior, data flows, and user interaction as part of the attack surface. Understanding how Azure services align across these areas helps security professionals apply familiar principles in new ways.

You learned to:

- Identify the five layers of an AI workload and how data moves through them
- Recognize three categories of AI-specific security risks
- Explain how Prompt Shields and Content Safety act as guardrails for model behavior
- Describe how Microsoft Defender for Cloud, Microsoft Purview, Microsoft Entra ID, and Azure AI Foundry form a connected security and governance framework

The challenge of applying established cloud security practices to AI workloads required a broader approach to protection. By combining posture management, data governance, model guardrails, and identity protection, Azure delivers a defense-in-depth strategy that secures AI systems across the entire lifecycle.

## Resources

- [What is Azure AI Foundry?](/azure/ai-foundry/what-is-azure-ai-foundry?azure-portal=true)
- [Enable threat protection for AI services](/azure/defender-for-cloud/ai-threat-protection?azure-portal=true)
- [Prompt Shields in Azure AI Content Safety](/azure/ai-services/content-safety/concepts/jailbreak-detection?azure-portal=true)
- [Azure AI Content Safety documentation](/azure/ai-services/content-safety?azure-portal=true)
- [Microsoft Purview documentation](/purview?azure-portal=true)
- [Microsoft Entra ID documentation](/entra/identity?azure-portal=true)
