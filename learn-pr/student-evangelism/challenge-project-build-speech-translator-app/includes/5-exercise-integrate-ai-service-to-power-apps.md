You're almost done. The last step is to make the features fully functional and maximize their capabilities by integrating AI into your solution.

## Specification

Update the app as follows:

- Add functionality to the microphone feature to capture what's being said and pass the input to Azure Blob Storage. After the blob is created, pass the Blob Storage container URL to the `AzureBatchSpeech-to-text` API to create a transcription.
- Add a button with functionality to trigger a Power Automate flow that takes care of the text translation. This button will also store the information sent back to the app by the Power Automate flow.
- Add functionality to the audio feature to read out the translated text.

Build a Power Automate flow that meets the following requirements:

1. The flow stores the transcription text, translated text, and text-to-speech audio file in variables to send back to the app.
2. The flow uses the transcription created and the transcription files to extract the text.
3. The flow uses the `Microsoft Translator V3` connector to translate the extracted text into the chosen language from the Power App.
4. The flow uses the `AzureTexttoSpeech` connector to convert the translated text into a speech audio file.

## Check your work

To validate that you've finished working on the requirements for this exercise, test your app behavior by following these steps:

1. Run your app and start a new translation.
2. Press the microphone control to record a speech.
3. Use the dropdown menu to select the translation language.
4. Press the button to trigger text-to-speech.
5. Listen to the translated text.

## Homework

Use the data model you created in unit 3 and store the information generated by the Power Automate flow in the tables you created.

**Congratulations!** Your commitment paid off. You built a speech translator application using low-code Power Apps and successfully integrated Microsoft Azure AI Speech. 
