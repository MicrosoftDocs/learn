 

When your company chooses Microsoft Fabric for end-to-end analytics, the first step is seamlessly ingesting data into your Fabric lakehouse. Consider the familiar extract, transform, load (ETL) process â€“ moving and transforming data. Depending on your role and data needs, you might focus on ingestion first or choose to cleanse and transform before loading. Fabric notebooks offer the flexibility to extract, load, and transform external data into your lakehouse, adapting to your workflow. While prior Spark or notebook experience is helpful, it's not mandatory.

Fabric notebooks are the best choice if you:

- Handle large external data
- Need complex transformations

By the end of this module, you'll be able to use Spark and Fabric notebooks to ingest external data into your lakehouse. You'll also learn fundamental transformations and optimization techniques for a more efficient ETL process.
