### YamlMime:Module
uid: learn.wwl.create-production-workloads-azure-databricks-azure-data-factory
metadata:
  title: Create production workloads on Azure Databricks with Azure Data Factory
  description: "Create production workloads on Azure Databricks with Azure Data Factory"
  ms.date: 05/15/2020
  author: jasallen
  ms.author: jasdeb
  ms.topic: interactive-tutorial
  ms.prod: learning-azure
title: Create production workloads on Azure Databricks with Azure Data Factory
summary: Azure Data Factory helps you create workflows that orchestrate data movement and transformation at scale. Integrate Azure Databricks into your production pipelines by calling notebooks and libraries.
abstract: |
  In this module, you'll:
  - Create an Azure Data Factory pipeline with a Databricks activity.
  - Execute a Databricks notebook with a parameter.
  - Retrieve and log a parameter passed back from the notebook.
  - Monitor your Data Factory pipeline.
prerequisites: |
  None
iconUrl: /learn/achievements/create-production-workloads-azure-databricks-azure-data-factory.svg
levels:
- intermediate
roles:
- data-engineer
products:
- azure-databricks
units:
- learn.wwl.create-production-workloads-azure-databricks-azure-data-factory.introduction
- learn.wwl.create-production-workloads-azure-databricks-azure-data-factory.schedule-databricks-jobs-pipeline
- learn.wwl.create-production-workloads-azure-databricks-azure-data-factory.pass-parameters-databricks-jobs
- learn.wwl.create-production-workloads-azure-databricks-azure-data-factory.knowledge-check
- learn.wwl.create-production-workloads-azure-databricks-azure-data-factory.summary
badge:
  uid: learn.wwl.create-production-workloads-azure-databricks-azure-data-factory.badge