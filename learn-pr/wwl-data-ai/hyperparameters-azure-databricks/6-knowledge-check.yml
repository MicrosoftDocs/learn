### YamlMime:ModuleUnit
uid: learn.wwl.hyperparameters-azure-databricks.knowledge-check
title: Module assessment
metadata:
  title: Module assessment
  description: Knowledge check
  author: wwlpublish
  ms.author: madiepev
  ms.date: 08/26/2024
  ms.topic: unit
  ms.collection:
    - wwl-ai-copilot
durationInMinutes: 3
quiz:
  title: ""
  questions:
  - content: "Which function should you use to initiate Hyperopt trials?"
    choices:
    - content: "hyperopt.tpe.suggest"
      isCorrect: false
      explanation: "Incorrect. The hyperopt.tpe.suggest constant is used to specify a TPE (Tree of Parzen Estimator) search algorithm."
    - content: "hyperopt.hp.choice"
      isCorrect: false
      explanation: "Incorrect. The hyperopt.htp.choice function defines an expression for a hyperparameter range."
    - content: "hyperopt.fmin"
      isCorrect: true
      explanation: "Correct. The fmin function controls the Hyperopt process to minimize an objective function."
  - content: "Which of these objects defines the set of hyperparameter values from which Hyperopt can sample when running trials?"
    choices:
    - content: "An *objective* function"
      isCorrect: false
      explanation: "Incorrect. An objective function doesn't define a set of possible hyperparameter values."
    - content: "A search space"
      isCorrect: true
      explanation: "Correct. A search space defines a set of possible hyperparameter values."
    - content: "A search algorithm"
      isCorrect: false
      explanation: "Incorrect. A search algorithm doesn't define a set of possible hyperparameter values."
  - content: "Which class should you use to track details of each hyperparameter tuning run when using Spark MLLib?"
    choices:
    - content: "Trials"
      isCorrect: true
      explanation: "Correct. The Trials class tracks details from each trial run."
    - content: "SparkTrials"
      isCorrect: false
      explanation: "Incorrect. SparkTrials is used to parallelize runs when using a nondistributed framework."
    - content: "RDD"
      isCorrect: false
      explanation: "Incorrect. An RDD (Resilient Distributed Datasets) is a core Spark structure for data."
