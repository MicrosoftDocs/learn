### YamlMime:ModuleUnit
uid: learn.wwl.hyperparameters-azure-databricks.knowledge-check
title: Module assessment
metadata:
  title: Module assessment
  description: Knowledge check
  author: JulianePadrao
  ms.author: jupadrao
  ms.date: 8/4/2025
  ms.topic: unit
  ms.collection:
    - wwl-ai-copilot
  module_assessment: true
durationInMinutes: 3
quiz:
  title: ""
  questions:
  - content: "Which method should you use to initiate Optuna optimization?"
    choices:
    - content: "optuna.trial.suggest"
      isCorrect: false
      explanation: "Incorrect. The suggest methods are used to define hyperparameter search spaces within the objective function."
    - content: "optuna.create_trial"
      isCorrect: false
      explanation: "Incorrect. This is not a valid Optuna method for starting optimization."
    - content: "study.optimize"
      isCorrect: true
      explanation: "Correct. The optimize method controls the Optuna optimization process to find the best hyperparameters."
  - content: "Which object in Optuna is used to define hyperparameter values for sampling during trials?"
    choices:
    - content: "An *objective* function"
      isCorrect: false
      explanation: "Incorrect. An objective function evaluates the model performance but doesn't define hyperparameter ranges."
    - content: "A trial object"
      isCorrect: true
      explanation: "Correct. The Trial object provides suggest methods to define hyperparameter search spaces."
    - content: "A sampler object"
      isCorrect: false
      explanation: "Incorrect. A Sampler implements sampling strategies but doesn't define the hyperparameter space."
  - content: "Which class should you use to track details of hyperparameter tuning when using Spark integration?"
    choices:
    - content: "SparkOptimizer"
      isCorrect: true
      explanation: "Correct. The SparkOptimizer class handles distributed optimization in Spark environments."
    - content: "Study"
      isCorrect: false
      explanation: "Incorrect. While Study manages optimization, SparkOptimizer is specifically for Spark integration."
    - content: "RDD"
      isCorrect: false
      explanation: "Incorrect. An RDD (Resilient Distributed Datasets) is a core Spark structure for data."