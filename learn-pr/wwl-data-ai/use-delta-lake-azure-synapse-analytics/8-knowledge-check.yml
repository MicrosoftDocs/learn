### YamlMime:ModuleUnit
uid: learn.wwl.use-delta-lake-azure-synapse-analytics.knowledge-check
title: Knowledge check
metadata:
  title: Knowledge check
  description: "Knowledge check"
  ms.date: 10/11/2023
  author: wwlpublish
  ms.author: jamesh
  ms.topic: unit
  ms.custom:
  - N/A
durationInMinutes: 5
quiz:
  title: ""
  questions:
  - content: "Which of the following descriptions best fits Delta Lake?"
    choices:
    - content: "A Spark API for exporting data from a relational database into CSV files."
      isCorrect: false
      explanation: "Incorrect. Delta Lake does not export data from a relational database into CSV files."
    - content: "A relational storage layer for Spark that supports tables based on Parquet files."
      isCorrect: true
      explanation: "Correct. Delta Lake provides a relational storage layer in which you can create tables based on Parquet files in a data lake."
    - content: "A synchronization solution that replicates data between SQL pools and Spark pools."
      isCorrect: false
      explanation: "Incorrect. Delta Lake does not replicate data between SQL pools and Spark pools."
  - content: "You've loaded a Spark dataframe with data, that you now want to use in a Delta Lake table. What format should you use to write the dataframe to storage?"
    choices:
    - content: "CSV"
      isCorrect: false
      explanation: "Incorrect. Delta Lake does not support tables based on CSV files."
    - content: "PARQUET"
      isCorrect: false
      explanation: "Incorrect. Although Delta Lake tables are based on Parquet files, the format must also include a transaction log."
    - content: "DELTA"
      isCorrect: true
      explanation: "Correct. Storing a dataframe in DELTA format creates parquet files for the data and the transaction log metadata necessary for Delta Lake tables."
  - content: "What feature of Delta Lake enables you to retrieve data from previous versions of a table?"
    choices:
    - content: "Spark Structured Streaming"
      isCorrect: false
      explanation: "Incorrect. Delta Lake tables do support Spark Structured Streaming, but that isn't what enables querying of previous versions."
    - content: "Time Travel"
      isCorrect: true
      explanation: "Correct. The Time Travel feature is based on the transaction log, which enables you to specify a version number or timestamp for the data you want to retrieve."
    - content: "Catalog Tables"
      isCorrect: false
      explanation: "Incorrect. You can create Catalog Tables for Delta Lake data, but that isn't what enables querying of previous versions."
  - content: "You have a managed catalog table that contains Delta Lake data. If you drop the table, what will happen?"
    choices:
    - content: "The table metadata and data files will be deleted."
      isCorrect: true
      explanation: "Correct. The life-cycle of the metadata and data for a managed table are the same."
    - content: "The table metadata will be removed from the catalog, but the data files will remain intact."
      isCorrect: false
      explanation: "Incorrect. The life-cycle of the metadata and data for a managed table are the same."
    - content: "The table metadata will remain in the catalog, but the data files will be deleted."
      isCorrect: false
      explanation: "Incorrect. The life-cycle of the metadata and data for a managed table are the same."
  - content: "When using Spark Structured Streaming, a Delta Lake table can be which of the following?"
    choices:
    - content: "Only a source"
      isCorrect: false
      explanation: "Incorrect. A Delta Lake table can be a source or a sink."
    - content: "Only a sink"
      isCorrect: false
      explanation: "Incorrect. A Delta Lake table can be a source or a sink."
    - content: "Either a source or a sink"
      isCorrect: true
      explanation: "Correct. A Delta Lake table can be a source or a sink."