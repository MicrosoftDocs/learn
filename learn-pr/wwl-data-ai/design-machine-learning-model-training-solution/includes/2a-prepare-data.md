Data is the foundation of machine learning. Both data quantity and data quality affect the model’s accuracy.

To train a machine learning model, you need to:

- Identify data source and format.
- Choose how to serve data.
- Design a data ingestion solution.

To **get and prepare the data** you use to train the machine learning model, you need to extract data from a source and make it available to the Azure service you want to use to train models or make predictions.

## Identify data source and format

First, you need to identify your data source and its current data format.

| Identify the | Examples|
|---|---|
| Data source | For example, the data can be stored in a Customer Relationship Management (CRM) system, in a transactional database like an SQL database, or be generated by an Internet of Things (IoT) device. |
| Data format | You need to understand the current format of the data, which can be tabular or structured data, semi-structured data or unstructured data. |

Then, you need to decide what data you need to train your model, and in what format you want that data to be served to the model.

## Design a data ingestion solution

In general, it’s a best practice to extract data from its source before analyzing it. Whether you’re using the data for data engineering, data analysis, or data science, you want to extract the data from its source, transform it, and load it into a serving layer. Such a process is also referred to as **Extract**, **Transform**, and **Load** (**ETL**) or **Extract**, **Load**, and **Transform** (**ELT**). The serving layer makes your data available for the service you use for further data processing like training machine learning models.

To move and transform data, you can use a **data ingestion pipeline**. A data ingestion pipeline is a sequence of tasks that move and transform the data. By creating a pipeline, you can choose to trigger the tasks manually or schedule the pipeline when you want the tasks to be automated. Such pipelines can be created with Azure services like Azure Synapse Analytics, Azure Databricks, and also Azure Machine Learning.

A common approach for a data ingestion solution is to:

1. Extract raw data from its source (like a CRM system or IoT device).
1. Copy and transform the data with Azure Synapse Analytics.
1. Store the prepared data in an Azure Blob Storage.
1. Train the model with Azure Machine Learning.

:::image type="content" source="../media/data-ingestion-pipeline.png" alt-text="Diagram showing an example of a data ingestion pipeline.":::

## Explore an example

Imagine you want to train a weather forecasting model. You prefer one table in which all temperature measurements of each minute are combined. You want to create aggregates of the data and have a table of the average temperature per hour. To create the table, you want to transform the semi-structured data ingested from the IoT device that measures temperature at intervals, to tabular data.

:::image type="content" source="../media/json-to-table.png" alt-text="Diagram showing an example of JSON data converted to a table.":::

For example, to create a dataset you can use to train the forecasting model, you can:

1. Extract data measurements as JSON objects from the IoT devices.
1. Convert the JSON objects to a table.
1. Transform the data to get the temperature per machine per minute.

Next, let's explore the services we can use to train machine learning models.