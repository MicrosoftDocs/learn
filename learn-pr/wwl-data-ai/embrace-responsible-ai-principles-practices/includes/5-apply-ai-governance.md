

No matter which governance approach you choose, there are some good practices it should promote:

* **Make resources available:** Employees need guidance to learn responsible AI principles and incorporate them into their work. A handbook, a manual, or a training session can fulfill that task. 

* **Create a centralized AI inventory:** Having a list of all the AI models and systems operating in your organization is key to prioritize efforts and optimize resources. Besides, it's also helpful to make audits and compliance tests easier.

* **Develop tools:** Checking compliance in every AI system in your organization can be draining. Consider building tools to automate this task: such tools would monitor and validate systems and raise a flag if anything shifts outside of performance metrics.

The specific processes and policies for your AI governance system depend on whether your company is using third-party systems or developing AI in-house. Based on this factor, we have provided recommendations to help your company govern your AI engagements.

## Third-party AI systems

If your organization plans to use out-of-the-box third-party AI solutions, we recommend learning about the third party’s commitment to responsible AI design to ensure it aligns with your own principles.

For custom AI solutions, include your principles or standards in your request for proposal. Before deploying any third-party AI solution, create guidelines on how to safely operate and monitor the system. Train employees on these guidelines and ensure they're being followed. Finally, your governance system should ensure the AI system has been rigorously tested.

## First-party AI systems

If your organization also plans to develop AI solutions or integrate AI into your existing products and services, there are some tasks for each team role.

Your **ethical governance system** should:
* Review or provide advice before the release of any new AI system, especially for sensitive use cases.

* Ensure employees from all levels of the company feel free to surface ethical concerns before you sell AI or AI-integrated products and services.

* Analyze the case and provide guidance to mitigate the risks if concerns arise while designing, developing, or selling the AI system.

* Create processes to monitor the AI systems you deploy or sell to detect and mitigate model drift and decay over time.

Your **developers** should:

* Be given detailed and thorough standard guidance that can help them design and develop AI solutions to reflect your organization’s ethical principles.

* Have guidelines and checklists for specific AI technologies, such as face recognition or generative AI.

## Engage with external stakeholders

As the use of AI becomes more common, we consider it a shared responsibility across the public and private sectors to engage with AI responsibly. Collaboration between enterprises, public organizations, governments, and nonprofits is crucial to ensure best practices while maximizing the potential of AI to deliver broad benefits.

Organizations can contribute to these collective efforts in many ways. At Microsoft, we have focused on joining industry initiatives, influencing policy, addressing future labor and workplace needs, and considering how our technologies can be used to improve the lives of people around the world. For example, we have joined the **Partnership on AI (PAI)**, a group of researchers, nonprofits, nongovernmental organizations (NGOs), and companies dedicated to ensuring that AI is developed and utilized in a responsible manner.

Next, let's discover how an AI governance system works in a real company using Microsoft as an example.
