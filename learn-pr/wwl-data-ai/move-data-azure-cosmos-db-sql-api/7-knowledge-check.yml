### YamlMime:ModuleUnit
uid: learn.wwl.moving-data-into-out-of-azure-cosmos-db-sql-api.knowledge-check
title: Knowledge check
metadata:
  title: Knowledge check
  description: "Knowledge check"
  ms.date: 04/02/2025
  author: wwlpublish
  ms.author: calopez
  ms.topic: unit
azureSandbox: false
labModal: false
durationInMinutes: 5
quiz:
  questions:
  - content: "Which type of component in Azure Data Factory will load data out to Azure Cosmos DB for NoSQL after it transforms?"
    choices:
    - content: "Sink"
      isCorrect: true
      explanation: "Correct. A sink is the destination for data after it transforms."
    - content: "Source"
      isCorrect: false
      explanation: "Incorrect. A source is the data that is ingested before the transformation."
    - content: "Input"
      isCorrect: false
      explanation: "Incorrect. An input is extra data that can be used in the ETL (Extract, Transform, and Load) process."
  - content: "After Azure Synapse Link is enabled at the Azure Cosmos DB for NoSQL account level, what should be done before the Spark connector can be used with a specific container?"
    choices:
    - content: "Install Apache Spark in Azure Cosmos DB for NoSQL"
      isCorrect: false
      explanation: "Incorrect. Apache Spark can't be installed in Azure Cosmos DB for NoSQL."
    - content: "No further action is necessary after enabling Azure Synapse Link"
      isCorrect: false
      explanation: "Incorrect. Enabling Azure Synapse Link isn't enough to use the Spark connector with a specific container."
    - content: "Enable analytical storage at the container level"
      isCorrect: true
      explanation: "Correct. Each container should have analytical storage enabled."
