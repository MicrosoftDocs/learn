There are various use cases that make using notebooks compelling within Azure Synapse Analytics

## To perform exploratory data analysis using a familiar paradigm

Many data engineers and data scientist work with Apache Spark in various incarnations, be it Microsoft Azure HDInsight, Azure Databricks, or even open-source Apache Spark. The notebooks that are available within Azure Synapse Analytics contain many of the features that these professionals are used to when working with notebooks to explore the data within their organizations. It enables data engineers and scientists to quickly launch a notebook to explore data without the need to learn a new tool, while taking advantage of the inherent integration that the notebooks in Azure Synapse Analytics has with other aspects of the product.

## To integrate notebooks as part of a broader data transformation process

Running complex or large transformation on an Apache Spark cluster is at times far more efficient than trying to perform the transformation using traditional relational Transact-SQL methods. You can use notebooks to perform transformations using Apache Spark, and then integrate this transformation into a broader extract, transform, and load (ETL) process by integrating the notebook into an ETL tool such as Azure Data Factory, or Azure Synapse pipelines.

## You wish to perform advanced analytics using notebooks with Azure Machine Learning Services

You can create Apache Spark tables in a notebook to connect to a linked service for Azure Machine Learning Services to perform various advanced analytical tasks from classical machine learning to deep learning, both supervised and unsupervised. Whether you prefer to write Python or R code with the SDK or work with no-code/low-code options in Azure Machine Learning Studio, you can build and train machine learning and deep-learning models using the notebooks, and track their activity in an Azure Machine Learning Workspace.
