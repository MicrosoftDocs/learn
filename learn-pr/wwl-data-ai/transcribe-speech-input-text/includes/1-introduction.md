The Azure AI Speech service provides APIs that you can use to build speech-enabled applications. Specifically, the Azure AI Speech service supports:

- **speech to text**: An API that enables *speech recognition* in which your application can accept spoken input.
- **Text to speech**: An API that enables *speech synthesis* in which your application can provide spoken output.
- **Speech Translation**: An API that you can use to translate spoken input into multiple languages.
- **Speaker Recognition**: An API that enables your application to recognize individual speakers based on their voice.
- **Intent Recognition**: An API that integrates with the **Language Understanding** service to determine the semantic meaning of spoken input.

This module focuses on speech recognition and speech synthesis, which are core capabilities of any speech-enabled application.

## Learning objectives

In this module, you'll learn how to: 

- Provision an Azure resource for the Azure AI Speech service
- Use the Azure AI Speech to text API to implement speech recognition
- Use the Text to speech API to implement speech synthesis
- Configure audio format and voices
- Use Speech Synthesis Markup Language (SSML)

The units in the module include important conceptual information about the Azure AI Speech service and how to use its API through one of the supported software development kits (SDKs), after which you'll be able to try the Azure AI Speech service for yourself in a hands-on exercise. To complete the hands-on exercise, you will need a Microsoft Azure subscription. If you don't already have one, you can sign up for a free trial at [https://azure.com/free](https://azure.com/free?azure-portal=true). 
