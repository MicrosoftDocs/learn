
Azure AI Speech provides APIs that you can use to build speech-enabled applications. This includes:

- **Speech to text**: An API that enables *speech recognition* in which your application can accept spoken input.
- **Text to speech**: An API that enables *speech synthesis* in which your application can provide spoken output.
- **Speech Translation**: An API that you can use to translate spoken input into multiple languages.
- **Speaker Recognition**: An API that enables your application to recognize individual speakers based on their voice.
- **Intent Recognition**: An API that uses conversational language understanding to determine the semantic meaning of spoken input.

This module focuses on speech recognition and speech synthesis, which are core capabilities of any speech-enabled application.

In this module, you'll learn how to:

- Provision an Azure resource for the Azure AI Speech service
- Use the Speech to text API to implement speech recognition
- Use the Text to speech API to implement speech synthesis
- Configure audio format and voices
- Use Speech Synthesis Markup Language (SSML)

The units in the module include important conceptual information about Azure AI Speech and how to use its API through one of the supported software development kits (SDKs), after which you'll be able to try Azure AI Speech for yourself in a hands-on exercise. To complete the hands-on exercise, you will need a Microsoft Azure subscription. If you don't already have one, you can sign up for a free trial at [https://azure.com/free](https://azure.com/free?azure-portal=true).