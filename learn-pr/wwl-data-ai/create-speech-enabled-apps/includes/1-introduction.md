
Azure AI Speech provides APIs that you can use to build speech-enabled applications. This includes:

- **Speech to text**: An API that enables *speech recognition* in which your application can accept spoken input.
- **Text to speech**: An API that enables *speech synthesis* in which your application can provide spoken output.
- **Speech Translation**: An API that you can use to translate spoken input into multiple languages.
- **Keyword Recognition**: An API that enables your application to recognize keywords or short phrases.
- **Intent Recognition**: An API that uses conversational language understanding to determine the semantic meaning of spoken input.

This module focuses on speech recognition and speech synthesis, which are core capabilities of any speech-enabled application.

> [!NOTE]
> The code examples in this module are provided in Python, but you can use any of the available Azure AI Speech SDK packages to develop speech-enabled applications in your preferred language. Available SDK packages include:
>
> - [azure-cognitiveservices-speech for Python](https://pypi.org/project/azure-cognitiveservices-speech?azure-portal=true)
> - [Microsoft.CognitiveServices.Speech for Microsoft .NET](https://www.nuget.org/packages/Microsoft.CognitiveServices.Speech?azure-portal=true)
> - [microsoft-cognitiveservices-speech-sdk for JavaScript](https://www.npmjs.com/package/microsoft-cognitiveservices-speech-sdk?azure-portal=true)
> - [Microsoft Cognitive Services Speech SDK For Java](https://mvnrepository.com/artifact/com.microsoft.cognitiveservices.speech/client-sdk?azure-portal=true)
