### YamlMime:ModuleUnit
uid: learn.wwl.perform-advanced-streaming-data-transformations-with-spark-kafka.knowledge-check
title: Knowledge check
metadata:
  title: Knowledge check
  description: "Knowledge check"
  ms.date: 04/07/2024
  author: wwlpublish
  ms.author: jamesh
  ms.topic: unit
azureSandbox: false
labModal: false
durationInMinutes: 3
quiz:
  questions:
  - content: "What API does Spark use to read data from Kafka?"
    choices:
    - content: "spark.readStream()."
      isCorrect: true
      explanation: "Correct. The Spark notebook uses spark.readStream to read data from the Kafka cluster."
    - content: "read.Stream()."
      isCorrect: false
      explanation: "No. `read.Stream` is the R method to read data from a stream."
    - content: "spark.writeStream()."
      isCorrect: false
      explanation: "No. spark.writeStream writes data to the stream."
  - content: "Which of the following parameters can't be used to read data from Kafka?"
    choices:
    - content: "Window."
      isCorrect: true
      explanation: "Correct. Window isn't a required parameter."
    - content: "Offset."
      isCorrect: false
      explanation: "Incorrect. Offset is a required parameter."
    - content: "Broker connection string."
      isCorrect: false
      explanation: "Incorrect. The broker connection string is a required parameter."
  - content: "Which scenario is best suited for using Spark Structured Streaming in Azure HDInsight?"
    choices:
    - content: "Running reports on a nightly basis and saving the reports for future use."
      isCorrect: false
      explanation: "Incorrect. Running reports for future use is best suited by a data warehousing solution."
    - content: "Creating adhoc queries on historical data."
      isCorrect: false
      explanation: "Incorrect. Adhoc queries are best served by using Interactive Query clusters for HDInsight."
    - content: "Running continuous jobs on streaming data."
      isCorrect: true
      explanation: "Correct, running continuous jobs on click stream analytics streaming from a website is a good solution for Spark Structured Streaming."