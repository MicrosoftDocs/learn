### YamlMime:ModuleUnit
uid: learn.wwl.understand-big-data-engineering-with-apache-spark-azure-synapse-analytics.knowledge-check
title: Knowledge check
metadata:
  title: Knowledge check
  description: "Knowledge check"
  ms.date: 05/25/2023
  author: wwlpublish
  ms.author: jamesh
  ms.topic: interactive-tutorial
  ms.prod: learning-azure
azureSandbox: false
labModal: false
durationInMinutes: 3
quiz:
  title: "Check your knowledge"
  questions:
  - content: "Which definition best describes Apache Spark?"
    choices:
    - content: "A highly scalable relational database management system."
      isCorrect: false
      explanation: "Incorrect. Spark supports some features of relational databases, but it isn't primarily a relational database engine."
    - content: "A virtual server with a Python runtime."
      isCorrect: false
      explanation: "Incorrect. Spark supports Python, but it isn't a single virtual server."
    - content: "A distributed platform for parallel data processing using multiple languages."
      isCorrect: true
      explanation: "Correct. Spark provides a highly scalable distributed platform on which you can run code written in many languages to process data."
  - content: "You need to use Spark to analyze data in a parquet file. What should you do?"
    choices:
    - content: "Load the parquet file into a dataframe."
      isCorrect: true
      explanation: "Correct. You can load data from files in many formats, including parquet, into a Spark dataframe."
    - content: "Import the data into a table in a serverless SQL pool."
      isCorrect: false
      explanation: "Incorrect. You don't need to load the data into a SQL pool in order to analyze it with Spark."
    - content: "Convert the data to CSV format."
      isCorrect: false
      explanation: "Incorrect. While you could load the data into Spark from a CSV file, you don't need to convert the data from parquet format in order to use it in Spark."
  - content: "You want to write code in a notebook cell that uses a SQL query to retrieve data from a view in the Spark catalog. Which magic should you use?"
    choices:
    - content: "%%spark"
      isCorrect: false
      explanation: "Incorrect. The %%spark magic instructs Spark to interpret the code in the cell as Scala."
    - content: "%%pyspark"
      isCorrect: false
      explanation: "Incorrect. The %%pyspark magic instructs Spark to interpret the code in the cell as Python."
    - content: "%%sql"
      isCorrect: true
      explanation: "Correct. The %%sql magic instructs Spark to interpret the code in the cell as SQL."