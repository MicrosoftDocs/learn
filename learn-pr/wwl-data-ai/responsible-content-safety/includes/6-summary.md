The proliferation of user-generated content makes it near-impossible for human moderators to effectively manage online platforms. Yet as the amount of user-generated content grows, so does the importance of online safety.

Azure AI Foundry Content Safety uses AI models to automatically detect violent, sexual, self-harm, or hateful language in real time. It allocates a severity level, so that human moderators can focus on high-priority cases and be exposed to a smaller amount of disturbing content. Foundry Content Safety includes features to moderate both people-generated and AI-generated material.

In this module, you've seen how the features of Foundry Content Safety can help e-commerce brands, gaming companies, and educators to provide safer spaces for users.
